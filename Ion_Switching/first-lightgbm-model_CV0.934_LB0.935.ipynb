{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error, f1_score\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from multiprocessing import Lock, Process, Queue, current_process\n",
    "import scipy as sp\n",
    "from functools import partial\n",
    "from numba import jit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import gc\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH =\"\"# \"../input/liverpool-ion-switching\"\n",
    "\n",
    "train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "submission_df = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f535d00e6144578bfa119221d44907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "for batch_size in tqdm_notebook([10000, 25000, 50000]):\n",
    "    train['batch'] = ((train['time'] * 10000) - 1) // batch_size\n",
    "    train['batch_index'] = ((train['time'] * 10000) - 1)  - (train['batch'] * batch_size) #10_000 is same as 10000.\n",
    "    train['batch_slices'] = train['batch_index']  // (batch_size / 10)\n",
    "    train['batch_slices2'] = train['batch'].astype(str).str.zfill(3) + '_' + train['batch_slices'].astype(str).str.zfill(3) #zfill() is zero patting function\n",
    "    \n",
    "    for agg_feature in ['batch', 'batch_slices2']:\n",
    "        train[f\"min_{agg_feature}_{batch_size}\"] = train.groupby(agg_feature)['signal'].transform('min')\n",
    "        train[f\"max_{agg_feature}_{batch_size}\"] = train.groupby(agg_feature)['signal'].transform('max')\n",
    "        train[f\"std_{agg_feature}_{batch_size}\"] = train.groupby(agg_feature)['signal'].transform('std')\n",
    "        train[f\"mean_{agg_feature}_{batch_size}\"] = train.groupby(agg_feature)['signal'].transform('mean')\n",
    "        \n",
    "        train[f\"min_{agg_feature}_{batch_size}_diff\"] = train[f\"min_{agg_feature}_{batch_size}\"] - train['signal']\n",
    "        train[f\"max_{agg_feature}_{batch_size}_diff\"] = train[f\"max_{agg_feature}_{batch_size}\"] - train['signal']\n",
    "        train[f\"std_{agg_feature}_{batch_size}_diff\"] = train[f\"std_{agg_feature}_{batch_size}\"] - train['signal']\n",
    "        train[f\"mean_{agg_feature}_{batch_size}_diff\"] = train[f\"mean_{agg_feature}_{batch_size}\"] - train['signal']\n",
    "        \n",
    "        train[f'signal_shift+1_{agg_feature}_{batch_size}'] = train.groupby([agg_feature]).shift(1)['signal']\n",
    "        train[f'signal_shift-1_{agg_feature}_{batch_size}'] = train.groupby([agg_feature]).shift(-1)['signal']\n",
    "        train[f'signal_shift+2_{agg_feature}_{batch_size}'] = train.groupby([agg_feature]).shift(2)['signal']\n",
    "        train[f'signal_shift-2_{agg_feature}_{batch_size}'] = train.groupby([agg_feature]).shift(-2)['signal']\n",
    "        gc.collect()\n",
    "\n",
    "    window_sizes = [ 1000, 5000, 10000]#100, 500,10, 25, 50, 25000, 30000]\n",
    "    for window in window_sizes:\n",
    "        train[\"rolling_maen_\" + str(window) + '_batch_' + str(batch_size)] = train.groupby('batch')['signal'].rolling(window=window).mean().reset_index()['signal']\n",
    "        train[\"rolling_std_\" + str(window) + '_batch_' + str(batch_size)] = train.groupby('batch')['signal'].rolling(window=window).std().reset_index()['signal']\n",
    "        #train[\"rolling_var_\" + str(window) + '_batch_' + str(batch_size)] = train.groupby('batch')['signal'].rolling(window=window).var().reset_index()['signal']\n",
    "        train[\"rolling_min_\" + str(window) + '_batch_' + str(batch_size)] = train.groupby('batch')['signal'].rolling(window=window).min().reset_index()['signal']\n",
    "        train[\"rolling_max_\" + str(window) + '_batch_' + str(batch_size)] = train.groupby('batch')['signal'].rolling(window=window).max().reset_index()['signal']\n",
    "        #train[\"rolling_median_\" + str(window) + '_batch_' + str(batch_size)] = train.groupby('batch')['signal'].rolling(window=window).median().reset_index()['signal']\n",
    "        #train[\"rolling_min_max_ratio_\" + str(window)+ '_batch_' + str(batch_size)] = train[\"rolling_min_\" + str(window)+ '_batch_' + str(batch_size)] / train[\"rolling_max_\" + str(window)+ '_batch_' + str(batch_size)]\n",
    "        #train[\"rolling_min_max_diff_\" + str(window)+ '_batch_' + str(batch_size)] = train[\"rolling_max_\" + str(window)+ '_batch_' + str(batch_size)] - train[\"rolling_min_\" + str(window)+ '_batch_' + str(batch_size)]\n",
    "        #train[\"rolling_min_max_mean_\" + str(window)+ '_batch_' + str(batch_size)] = (train[\"rolling_max_\" + str(window)+ '_batch_' + str(batch_size)] + train[\"rolling_min_\" + str(window)+ '_batch_' + str(batch_size)])/2\n",
    "        a = (train['signal'] - train['rolling_min_' + str(window)+ '_batch_' + str(batch_size)]) / (train['rolling_max_' + str(window)+ '_batch_' + str(batch_size)] - train['rolling_min_' + str(window)+ '_batch_' + str(batch_size)])\n",
    "        train[\"norm_\" + str(window)+ '_batch_' + str(batch_size)] = a * (np.floor(train['rolling_max_' + str(window)+ '_batch_' + str(batch_size)]) - np.ceil(train['rolling_min_' + str(window)+ '_batch_' + str(batch_size)]))\n",
    "        del a\n",
    "        gc.collect()\n",
    "\n",
    "        ewma = pd.Series.ewm\n",
    "\n",
    "        train[f'exp_Moving__{window}_{batch_size}'] = train.groupby('batch')['signal'].apply(lambda x: x.ewm(alpha=0.5, adjust=False).mean())\n",
    "train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=train.drop([\"batch_slices2\"],axis=1) #drop categoricaldata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1254.08 Mb (75.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "train=reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49257709808b4016954a53c3ad413d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "for batch_size in tqdm_notebook([10000, 25000, 50000]):\n",
    "    test['batch'] = ((test['time'] * 10000) - 1) // batch_size\n",
    "    test['batch_index'] = ((test['time'] * 10000) - 1)  - (test['batch'] * batch_size) #10_000 is same as 10000.\n",
    "    test['batch_slices'] = test['batch_index']  // (batch_size / 10)\n",
    "    test['batch_slices2'] = test['batch'].astype(str).str.zfill(3) + '_' + test['batch_slices'].astype(str).str.zfill(3) #zfill() is zero patting function\n",
    "    \n",
    "    for agg_feature in ['batch', 'batch_slices2']:\n",
    "        test[f\"min_{agg_feature}_{batch_size}\"] = test.groupby(agg_feature)['signal'].transform('min')\n",
    "        test[f\"max_{agg_feature}_{batch_size}\"] = test.groupby(agg_feature)['signal'].transform('max')\n",
    "        test[f\"std_{agg_feature}_{batch_size}\"] = test.groupby(agg_feature)['signal'].transform('std')\n",
    "        test[f\"mean_{agg_feature}_{batch_size}\"] = test.groupby(agg_feature)['signal'].transform('mean')\n",
    "        \n",
    "        test[f\"min_{agg_feature}_{batch_size}_diff\"] = test[f\"min_{agg_feature}_{batch_size}\"] - test['signal']\n",
    "        test[f\"max_{agg_feature}_{batch_size}_diff\"] = test[f\"max_{agg_feature}_{batch_size}\"] - test['signal']\n",
    "        test[f\"std_{agg_feature}_{batch_size}_diff\"] = test[f\"std_{agg_feature}_{batch_size}\"] - test['signal']\n",
    "        test[f\"mean_{agg_feature}_{batch_size}_diff\"] = test[f\"mean_{agg_feature}_{batch_size}\"] - test['signal']\n",
    "        \n",
    "        test[f'signal_shift+1_{agg_feature}_{batch_size}'] = test.groupby([agg_feature]).shift(1)['signal']\n",
    "        test[f'signal_shift-1_{agg_feature}_{batch_size}'] = test.groupby([agg_feature]).shift(-1)['signal']\n",
    "        test[f'signal_shift+2_{agg_feature}_{batch_size}'] = test.groupby([agg_feature]).shift(2)['signal']\n",
    "        test[f'signal_shift-2_{agg_feature}_{batch_size}'] = test.groupby([agg_feature]).shift(-2)['signal']\n",
    "        gc.collect()\n",
    "\n",
    "    window_sizes = [1000, 5000, 10000]#10, 25, 50, 100, 500, , 25000, 30000\n",
    "    for window in window_sizes:\n",
    "        test[\"rolling_maen_\" + str(window) + '_batch_' + str(batch_size)] = test.groupby('batch')['signal'].rolling(window=window).mean().reset_index()['signal']\n",
    "        test[\"rolling_std_\" + str(window) + '_batch_' + str(batch_size)] = test.groupby('batch')['signal'].rolling(window=window).std().reset_index()['signal']\n",
    "        #test[\"rolling_var_\" + str(window) + '_batch_' + str(batch_size)] = test.groupby('batch')['signal'].rolling(window=window).var().reset_index()['signal']\n",
    "        test[\"rolling_min_\" + str(window) + '_batch_' + str(batch_size)] = test.groupby('batch')['signal'].rolling(window=window).min().reset_index()['signal']\n",
    "        test[\"rolling_max_\" + str(window) + '_batch_' + str(batch_size)] = test.groupby('batch')['signal'].rolling(window=window).max().reset_index()['signal']\n",
    "        #test[\"rolling_median_\" + str(window) + '_batch_' + str(batch_size)] = test.groupby('batch')['signal'].rolling(window=window).median().reset_index()['signal']\n",
    "        #test[\"rolling_min_max_ratio_\" + str(window)+ '_batch_' + str(batch_size)] = test[\"rolling_min_\" + str(window)+ '_batch_' + str(batch_size)] / test[\"rolling_max_\" + str(window)+ '_batch_' + str(batch_size)]\n",
    "        #test[\"rolling_min_max_diff_\" + str(window)+ '_batch_' + str(batch_size)] = test[\"rolling_max_\" + str(window)+ '_batch_' + str(batch_size)] - test[\"rolling_min_\" + str(window)+ '_batch_' + str(batch_size)]\n",
    "        #test[\"rolling_min_max_mean_\" + str(window)+ '_batch_' + str(batch_size)] = (test[\"rolling_max_\" + str(window)+ '_batch_' + str(batch_size)] + test[\"rolling_min_\" + str(window)+ '_batch_' + str(batch_size)])/2\n",
    "        a = (test['signal'] - test['rolling_min_' + str(window)+ '_batch_' + str(batch_size)]) / (test['rolling_max_' + str(window)+ '_batch_' + str(batch_size)] - test['rolling_min_' + str(window)+ '_batch_' + str(batch_size)])\n",
    "        test[\"norm_\" + str(window)+ '_batch_' + str(batch_size)] = a * (np.floor(test['rolling_max_' + str(window)+ '_batch_' + str(batch_size)]) - np.ceil(test['rolling_min_' + str(window)+ '_batch_' + str(batch_size)]))\n",
    "\n",
    "        del a\n",
    "        gc.collect()\n",
    "        ewma = pd.Series.ewm\n",
    "\n",
    "        test[f'exp_Moving__{window}_{batch_size}'] = test.groupby('batch')['signal'].apply(lambda x: x.ewm(alpha=0.5, adjust=False).mean())\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=test.drop([\"batch_slices2\"],axis=1) #drop categoricaldata\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 499.73 Mb (75.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "test=reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(columns=['time'])\n",
    "test=test.drop(columns=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "      <th>open_channels</th>\n",
       "      <th>batch</th>\n",
       "      <th>batch_index</th>\n",
       "      <th>batch_slices</th>\n",
       "      <th>min_batch_10000</th>\n",
       "      <th>max_batch_10000</th>\n",
       "      <th>std_batch_10000</th>\n",
       "      <th>mean_batch_10000</th>\n",
       "      <th>min_batch_10000_diff</th>\n",
       "      <th>max_batch_10000_diff</th>\n",
       "      <th>std_batch_10000_diff</th>\n",
       "      <th>mean_batch_10000_diff</th>\n",
       "      <th>signal_shift+1_batch_10000</th>\n",
       "      <th>signal_shift-1_batch_10000</th>\n",
       "      <th>signal_shift+2_batch_10000</th>\n",
       "      <th>signal_shift-2_batch_10000</th>\n",
       "      <th>min_batch_slices2_10000</th>\n",
       "      <th>max_batch_slices2_10000</th>\n",
       "      <th>std_batch_slices2_10000</th>\n",
       "      <th>mean_batch_slices2_10000</th>\n",
       "      <th>min_batch_slices2_10000_diff</th>\n",
       "      <th>max_batch_slices2_10000_diff</th>\n",
       "      <th>std_batch_slices2_10000_diff</th>\n",
       "      <th>mean_batch_slices2_10000_diff</th>\n",
       "      <th>signal_shift+1_batch_slices2_10000</th>\n",
       "      <th>signal_shift-1_batch_slices2_10000</th>\n",
       "      <th>signal_shift+2_batch_slices2_10000</th>\n",
       "      <th>signal_shift-2_batch_slices2_10000</th>\n",
       "      <th>rolling_maen_1000_batch_10000</th>\n",
       "      <th>rolling_std_1000_batch_10000</th>\n",
       "      <th>rolling_min_1000_batch_10000</th>\n",
       "      <th>rolling_max_1000_batch_10000</th>\n",
       "      <th>norm_1000_batch_10000</th>\n",
       "      <th>exp_Moving__1000_10000</th>\n",
       "      <th>rolling_maen_5000_batch_10000</th>\n",
       "      <th>rolling_std_5000_batch_10000</th>\n",
       "      <th>rolling_min_5000_batch_10000</th>\n",
       "      <th>rolling_max_5000_batch_10000</th>\n",
       "      <th>norm_5000_batch_10000</th>\n",
       "      <th>exp_Moving__5000_10000</th>\n",
       "      <th>rolling_maen_10000_batch_10000</th>\n",
       "      <th>rolling_std_10000_batch_10000</th>\n",
       "      <th>rolling_min_10000_batch_10000</th>\n",
       "      <th>rolling_max_10000_batch_10000</th>\n",
       "      <th>norm_10000_batch_10000</th>\n",
       "      <th>exp_Moving__10000_10000</th>\n",
       "      <th>min_batch_25000</th>\n",
       "      <th>max_batch_25000</th>\n",
       "      <th>std_batch_25000</th>\n",
       "      <th>mean_batch_25000</th>\n",
       "      <th>min_batch_25000_diff</th>\n",
       "      <th>max_batch_25000_diff</th>\n",
       "      <th>std_batch_25000_diff</th>\n",
       "      <th>mean_batch_25000_diff</th>\n",
       "      <th>signal_shift+1_batch_25000</th>\n",
       "      <th>signal_shift-1_batch_25000</th>\n",
       "      <th>signal_shift+2_batch_25000</th>\n",
       "      <th>signal_shift-2_batch_25000</th>\n",
       "      <th>min_batch_slices2_25000</th>\n",
       "      <th>max_batch_slices2_25000</th>\n",
       "      <th>std_batch_slices2_25000</th>\n",
       "      <th>mean_batch_slices2_25000</th>\n",
       "      <th>min_batch_slices2_25000_diff</th>\n",
       "      <th>max_batch_slices2_25000_diff</th>\n",
       "      <th>std_batch_slices2_25000_diff</th>\n",
       "      <th>mean_batch_slices2_25000_diff</th>\n",
       "      <th>signal_shift+1_batch_slices2_25000</th>\n",
       "      <th>signal_shift-1_batch_slices2_25000</th>\n",
       "      <th>signal_shift+2_batch_slices2_25000</th>\n",
       "      <th>signal_shift-2_batch_slices2_25000</th>\n",
       "      <th>rolling_maen_1000_batch_25000</th>\n",
       "      <th>rolling_std_1000_batch_25000</th>\n",
       "      <th>rolling_min_1000_batch_25000</th>\n",
       "      <th>rolling_max_1000_batch_25000</th>\n",
       "      <th>norm_1000_batch_25000</th>\n",
       "      <th>exp_Moving__1000_25000</th>\n",
       "      <th>rolling_maen_5000_batch_25000</th>\n",
       "      <th>rolling_std_5000_batch_25000</th>\n",
       "      <th>rolling_min_5000_batch_25000</th>\n",
       "      <th>rolling_max_5000_batch_25000</th>\n",
       "      <th>norm_5000_batch_25000</th>\n",
       "      <th>exp_Moving__5000_25000</th>\n",
       "      <th>rolling_maen_10000_batch_25000</th>\n",
       "      <th>rolling_std_10000_batch_25000</th>\n",
       "      <th>rolling_min_10000_batch_25000</th>\n",
       "      <th>rolling_max_10000_batch_25000</th>\n",
       "      <th>norm_10000_batch_25000</th>\n",
       "      <th>exp_Moving__10000_25000</th>\n",
       "      <th>min_batch_50000</th>\n",
       "      <th>max_batch_50000</th>\n",
       "      <th>std_batch_50000</th>\n",
       "      <th>mean_batch_50000</th>\n",
       "      <th>min_batch_50000_diff</th>\n",
       "      <th>max_batch_50000_diff</th>\n",
       "      <th>std_batch_50000_diff</th>\n",
       "      <th>mean_batch_50000_diff</th>\n",
       "      <th>signal_shift+1_batch_50000</th>\n",
       "      <th>signal_shift-1_batch_50000</th>\n",
       "      <th>signal_shift+2_batch_50000</th>\n",
       "      <th>signal_shift-2_batch_50000</th>\n",
       "      <th>min_batch_slices2_50000</th>\n",
       "      <th>max_batch_slices2_50000</th>\n",
       "      <th>std_batch_slices2_50000</th>\n",
       "      <th>mean_batch_slices2_50000</th>\n",
       "      <th>min_batch_slices2_50000_diff</th>\n",
       "      <th>max_batch_slices2_50000_diff</th>\n",
       "      <th>std_batch_slices2_50000_diff</th>\n",
       "      <th>mean_batch_slices2_50000_diff</th>\n",
       "      <th>signal_shift+1_batch_slices2_50000</th>\n",
       "      <th>signal_shift-1_batch_slices2_50000</th>\n",
       "      <th>signal_shift+2_batch_slices2_50000</th>\n",
       "      <th>signal_shift-2_batch_slices2_50000</th>\n",
       "      <th>rolling_maen_1000_batch_50000</th>\n",
       "      <th>rolling_std_1000_batch_50000</th>\n",
       "      <th>rolling_min_1000_batch_50000</th>\n",
       "      <th>rolling_max_1000_batch_50000</th>\n",
       "      <th>norm_1000_batch_50000</th>\n",
       "      <th>exp_Moving__1000_50000</th>\n",
       "      <th>rolling_maen_5000_batch_50000</th>\n",
       "      <th>rolling_std_5000_batch_50000</th>\n",
       "      <th>rolling_min_5000_batch_50000</th>\n",
       "      <th>rolling_max_5000_batch_50000</th>\n",
       "      <th>norm_5000_batch_50000</th>\n",
       "      <th>exp_Moving__5000_50000</th>\n",
       "      <th>rolling_maen_10000_batch_50000</th>\n",
       "      <th>rolling_std_10000_batch_50000</th>\n",
       "      <th>rolling_min_10000_batch_50000</th>\n",
       "      <th>rolling_max_10000_batch_50000</th>\n",
       "      <th>norm_10000_batch_50000</th>\n",
       "      <th>exp_Moving__10000_50000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.759766</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.589844</td>\n",
       "      <td>-1.047852</td>\n",
       "      <td>0.243896</td>\n",
       "      <td>-2.697266</td>\n",
       "      <td>-0.829590</td>\n",
       "      <td>1.711914</td>\n",
       "      <td>3.003906</td>\n",
       "      <td>0.063232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-3.466797</td>\n",
       "      <td>-2.03125</td>\n",
       "      <td>0.242432</td>\n",
       "      <td>-2.693359</td>\n",
       "      <td>-0.707031</td>\n",
       "      <td>0.728027</td>\n",
       "      <td>3.001953</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-3.654297</td>\n",
       "      <td>-0.765137</td>\n",
       "      <td>0.272949</td>\n",
       "      <td>-2.683594</td>\n",
       "      <td>-0.895020</td>\n",
       "      <td>1.995117</td>\n",
       "      <td>3.033203</td>\n",
       "      <td>0.076233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-3.466797</td>\n",
       "      <td>-1.90332</td>\n",
       "      <td>0.244385</td>\n",
       "      <td>-2.693359</td>\n",
       "      <td>-0.707031</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>3.003906</td>\n",
       "      <td>0.066223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-3.662109</td>\n",
       "      <td>-0.765137</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>-2.6875</td>\n",
       "      <td>-0.902344</td>\n",
       "      <td>1.995117</td>\n",
       "      <td>3.021484</td>\n",
       "      <td>0.072815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-3.589844</td>\n",
       "      <td>-1.862305</td>\n",
       "      <td>0.24292</td>\n",
       "      <td>-2.695312</td>\n",
       "      <td>-0.829590</td>\n",
       "      <td>0.897461</td>\n",
       "      <td>3.003906</td>\n",
       "      <td>0.064392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.759766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.855469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.589844</td>\n",
       "      <td>-1.047852</td>\n",
       "      <td>0.243896</td>\n",
       "      <td>-2.697266</td>\n",
       "      <td>-0.733887</td>\n",
       "      <td>1.807617</td>\n",
       "      <td>3.099609</td>\n",
       "      <td>0.158936</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-3.466797</td>\n",
       "      <td>-2.03125</td>\n",
       "      <td>0.242432</td>\n",
       "      <td>-2.693359</td>\n",
       "      <td>-0.611328</td>\n",
       "      <td>0.823730</td>\n",
       "      <td>3.097656</td>\n",
       "      <td>0.162842</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.808594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.808594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.808594</td>\n",
       "      <td>-3.654297</td>\n",
       "      <td>-0.765137</td>\n",
       "      <td>0.272949</td>\n",
       "      <td>-2.683594</td>\n",
       "      <td>-0.799316</td>\n",
       "      <td>2.089844</td>\n",
       "      <td>3.128906</td>\n",
       "      <td>0.171997</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-3.466797</td>\n",
       "      <td>-1.90332</td>\n",
       "      <td>0.244385</td>\n",
       "      <td>-2.693359</td>\n",
       "      <td>-0.611328</td>\n",
       "      <td>0.952637</td>\n",
       "      <td>3.099609</td>\n",
       "      <td>0.161987</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.808594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.808594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.808594</td>\n",
       "      <td>-3.662109</td>\n",
       "      <td>-0.765137</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>-2.6875</td>\n",
       "      <td>-0.806641</td>\n",
       "      <td>2.089844</td>\n",
       "      <td>3.117188</td>\n",
       "      <td>0.168457</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-3.589844</td>\n",
       "      <td>-1.862305</td>\n",
       "      <td>0.24292</td>\n",
       "      <td>-2.695312</td>\n",
       "      <td>-0.733887</td>\n",
       "      <td>0.993164</td>\n",
       "      <td>3.099609</td>\n",
       "      <td>0.160034</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.808594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.808594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.808594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.408203</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.589844</td>\n",
       "      <td>-1.047852</td>\n",
       "      <td>0.243896</td>\n",
       "      <td>-2.697266</td>\n",
       "      <td>-1.182617</td>\n",
       "      <td>1.359375</td>\n",
       "      <td>2.650391</td>\n",
       "      <td>-0.289307</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>-3.466797</td>\n",
       "      <td>-2.03125</td>\n",
       "      <td>0.242432</td>\n",
       "      <td>-2.693359</td>\n",
       "      <td>-1.059570</td>\n",
       "      <td>0.375488</td>\n",
       "      <td>2.650391</td>\n",
       "      <td>-0.285400</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.607422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.607422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.607422</td>\n",
       "      <td>-3.654297</td>\n",
       "      <td>-0.765137</td>\n",
       "      <td>0.272949</td>\n",
       "      <td>-2.683594</td>\n",
       "      <td>-1.248047</td>\n",
       "      <td>1.642578</td>\n",
       "      <td>2.679688</td>\n",
       "      <td>-0.276367</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>-3.466797</td>\n",
       "      <td>-1.90332</td>\n",
       "      <td>0.244385</td>\n",
       "      <td>-2.693359</td>\n",
       "      <td>-1.059570</td>\n",
       "      <td>0.504395</td>\n",
       "      <td>2.652344</td>\n",
       "      <td>-0.286377</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.607422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.607422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.607422</td>\n",
       "      <td>-3.662109</td>\n",
       "      <td>-0.765137</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>-2.6875</td>\n",
       "      <td>-1.254883</td>\n",
       "      <td>1.642578</td>\n",
       "      <td>2.667969</td>\n",
       "      <td>-0.279785</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>-3.589844</td>\n",
       "      <td>-1.862305</td>\n",
       "      <td>0.24292</td>\n",
       "      <td>-2.695312</td>\n",
       "      <td>-1.182617</td>\n",
       "      <td>0.544922</td>\n",
       "      <td>2.650391</td>\n",
       "      <td>-0.288330</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.759766</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.607422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.607422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.607422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.140625</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.589844</td>\n",
       "      <td>-1.047852</td>\n",
       "      <td>0.243896</td>\n",
       "      <td>-2.697266</td>\n",
       "      <td>-0.449219</td>\n",
       "      <td>2.091797</td>\n",
       "      <td>3.384766</td>\n",
       "      <td>0.443604</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>-3.466797</td>\n",
       "      <td>-2.03125</td>\n",
       "      <td>0.242432</td>\n",
       "      <td>-2.693359</td>\n",
       "      <td>-0.326416</td>\n",
       "      <td>1.108398</td>\n",
       "      <td>3.382812</td>\n",
       "      <td>0.447510</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.873047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.873047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.873047</td>\n",
       "      <td>-3.654297</td>\n",
       "      <td>-0.765137</td>\n",
       "      <td>0.272949</td>\n",
       "      <td>-2.683594</td>\n",
       "      <td>-0.514648</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>3.414062</td>\n",
       "      <td>0.456543</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>-3.466797</td>\n",
       "      <td>-1.90332</td>\n",
       "      <td>0.244385</td>\n",
       "      <td>-2.693359</td>\n",
       "      <td>-0.326416</td>\n",
       "      <td>1.237305</td>\n",
       "      <td>3.384766</td>\n",
       "      <td>0.446533</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.873047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.873047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.873047</td>\n",
       "      <td>-3.662109</td>\n",
       "      <td>-0.765137</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>-2.6875</td>\n",
       "      <td>-0.521484</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>3.400391</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>-3.589844</td>\n",
       "      <td>-1.862305</td>\n",
       "      <td>0.24292</td>\n",
       "      <td>-2.695312</td>\n",
       "      <td>-0.449219</td>\n",
       "      <td>1.277344</td>\n",
       "      <td>3.382812</td>\n",
       "      <td>0.444824</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-3.152344</td>\n",
       "      <td>-2.855469</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.873047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.873047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.873047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.152344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.589844</td>\n",
       "      <td>-1.047852</td>\n",
       "      <td>0.243896</td>\n",
       "      <td>-2.697266</td>\n",
       "      <td>-0.437012</td>\n",
       "      <td>2.103516</td>\n",
       "      <td>3.396484</td>\n",
       "      <td>0.455811</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-2.699219</td>\n",
       "      <td>-3.466797</td>\n",
       "      <td>-2.03125</td>\n",
       "      <td>0.242432</td>\n",
       "      <td>-2.693359</td>\n",
       "      <td>-0.314453</td>\n",
       "      <td>1.120117</td>\n",
       "      <td>3.394531</td>\n",
       "      <td>0.459717</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-2.699219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.013672</td>\n",
       "      <td>-3.654297</td>\n",
       "      <td>-0.765137</td>\n",
       "      <td>0.272949</td>\n",
       "      <td>-2.683594</td>\n",
       "      <td>-0.502441</td>\n",
       "      <td>2.386719</td>\n",
       "      <td>3.425781</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-2.699219</td>\n",
       "      <td>-3.466797</td>\n",
       "      <td>-1.90332</td>\n",
       "      <td>0.244385</td>\n",
       "      <td>-2.693359</td>\n",
       "      <td>-0.314453</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.396484</td>\n",
       "      <td>0.458740</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-2.699219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.013672</td>\n",
       "      <td>-3.662109</td>\n",
       "      <td>-0.765137</td>\n",
       "      <td>0.260742</td>\n",
       "      <td>-2.6875</td>\n",
       "      <td>-0.509766</td>\n",
       "      <td>2.386719</td>\n",
       "      <td>3.414062</td>\n",
       "      <td>0.465332</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-2.699219</td>\n",
       "      <td>-3.589844</td>\n",
       "      <td>-1.862305</td>\n",
       "      <td>0.24292</td>\n",
       "      <td>-2.695312</td>\n",
       "      <td>-0.437012</td>\n",
       "      <td>1.290039</td>\n",
       "      <td>3.394531</td>\n",
       "      <td>0.456787</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>-2.642578</td>\n",
       "      <td>-2.408203</td>\n",
       "      <td>-2.699219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.013672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.013672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     signal  open_channels  batch  batch_index  batch_slices  min_batch_10000  \\\n",
       "0 -2.759766              0    0.0          0.0           0.0        -3.589844   \n",
       "1 -2.855469              0    0.0          1.0           0.0        -3.589844   \n",
       "2 -2.408203              0    0.0          2.0           0.0        -3.589844   \n",
       "3 -3.140625              0    0.0          3.0           0.0        -3.589844   \n",
       "4 -3.152344              0    0.0          4.0           0.0        -3.589844   \n",
       "\n",
       "   max_batch_10000  std_batch_10000  mean_batch_10000  min_batch_10000_diff  \\\n",
       "0        -1.047852         0.243896         -2.697266             -0.829590   \n",
       "1        -1.047852         0.243896         -2.697266             -0.733887   \n",
       "2        -1.047852         0.243896         -2.697266             -1.182617   \n",
       "3        -1.047852         0.243896         -2.697266             -0.449219   \n",
       "4        -1.047852         0.243896         -2.697266             -0.437012   \n",
       "\n",
       "   max_batch_10000_diff  std_batch_10000_diff  mean_batch_10000_diff  \\\n",
       "0              1.711914              3.003906               0.063232   \n",
       "1              1.807617              3.099609               0.158936   \n",
       "2              1.359375              2.650391              -0.289307   \n",
       "3              2.091797              3.384766               0.443604   \n",
       "4              2.103516              3.396484               0.455811   \n",
       "\n",
       "   signal_shift+1_batch_10000  signal_shift-1_batch_10000  \\\n",
       "0                    0.000000                   -2.855469   \n",
       "1                   -2.759766                   -2.408203   \n",
       "2                   -2.855469                   -3.140625   \n",
       "3                   -2.408203                   -3.152344   \n",
       "4                   -3.140625                   -2.642578   \n",
       "\n",
       "   signal_shift+2_batch_10000  signal_shift-2_batch_10000  \\\n",
       "0                    0.000000                   -2.408203   \n",
       "1                    0.000000                   -3.140625   \n",
       "2                   -2.759766                   -3.152344   \n",
       "3                   -2.855469                   -2.642578   \n",
       "4                   -2.408203                   -2.699219   \n",
       "\n",
       "   min_batch_slices2_10000  max_batch_slices2_10000  std_batch_slices2_10000  \\\n",
       "0                -3.466797                 -2.03125                 0.242432   \n",
       "1                -3.466797                 -2.03125                 0.242432   \n",
       "2                -3.466797                 -2.03125                 0.242432   \n",
       "3                -3.466797                 -2.03125                 0.242432   \n",
       "4                -3.466797                 -2.03125                 0.242432   \n",
       "\n",
       "   mean_batch_slices2_10000  min_batch_slices2_10000_diff  \\\n",
       "0                 -2.693359                     -0.707031   \n",
       "1                 -2.693359                     -0.611328   \n",
       "2                 -2.693359                     -1.059570   \n",
       "3                 -2.693359                     -0.326416   \n",
       "4                 -2.693359                     -0.314453   \n",
       "\n",
       "   max_batch_slices2_10000_diff  std_batch_slices2_10000_diff  \\\n",
       "0                      0.728027                      3.001953   \n",
       "1                      0.823730                      3.097656   \n",
       "2                      0.375488                      2.650391   \n",
       "3                      1.108398                      3.382812   \n",
       "4                      1.120117                      3.394531   \n",
       "\n",
       "   mean_batch_slices2_10000_diff  signal_shift+1_batch_slices2_10000  \\\n",
       "0                       0.067200                            0.000000   \n",
       "1                       0.162842                           -2.759766   \n",
       "2                      -0.285400                           -2.855469   \n",
       "3                       0.447510                           -2.408203   \n",
       "4                       0.459717                           -3.140625   \n",
       "\n",
       "   signal_shift-1_batch_slices2_10000  signal_shift+2_batch_slices2_10000  \\\n",
       "0                           -2.855469                            0.000000   \n",
       "1                           -2.408203                            0.000000   \n",
       "2                           -3.140625                           -2.759766   \n",
       "3                           -3.152344                           -2.855469   \n",
       "4                           -2.642578                           -2.408203   \n",
       "\n",
       "   signal_shift-2_batch_slices2_10000  rolling_maen_1000_batch_10000  \\\n",
       "0                           -2.408203                            0.0   \n",
       "1                           -3.140625                            0.0   \n",
       "2                           -3.152344                            0.0   \n",
       "3                           -2.642578                            0.0   \n",
       "4                           -2.699219                            0.0   \n",
       "\n",
       "   rolling_std_1000_batch_10000  rolling_min_1000_batch_10000  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   rolling_max_1000_batch_10000  norm_1000_batch_10000  \\\n",
       "0                           0.0                    0.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    0.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   exp_Moving__1000_10000  rolling_maen_5000_batch_10000  \\\n",
       "0               -2.759766                            0.0   \n",
       "1               -2.808594                            0.0   \n",
       "2               -2.607422                            0.0   \n",
       "3               -2.873047                            0.0   \n",
       "4               -3.013672                            0.0   \n",
       "\n",
       "   rolling_std_5000_batch_10000  rolling_min_5000_batch_10000  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   rolling_max_5000_batch_10000  norm_5000_batch_10000  \\\n",
       "0                           0.0                    0.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    0.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   exp_Moving__5000_10000  rolling_maen_10000_batch_10000  \\\n",
       "0               -2.759766                             0.0   \n",
       "1               -2.808594                             0.0   \n",
       "2               -2.607422                             0.0   \n",
       "3               -2.873047                             0.0   \n",
       "4               -3.013672                             0.0   \n",
       "\n",
       "   rolling_std_10000_batch_10000  rolling_min_10000_batch_10000  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                            0.0                            0.0   \n",
       "\n",
       "   rolling_max_10000_batch_10000  norm_10000_batch_10000  \\\n",
       "0                            0.0                     0.0   \n",
       "1                            0.0                     0.0   \n",
       "2                            0.0                     0.0   \n",
       "3                            0.0                     0.0   \n",
       "4                            0.0                     0.0   \n",
       "\n",
       "   exp_Moving__10000_10000  min_batch_25000  max_batch_25000  std_batch_25000  \\\n",
       "0                -2.759766        -3.654297        -0.765137         0.272949   \n",
       "1                -2.808594        -3.654297        -0.765137         0.272949   \n",
       "2                -2.607422        -3.654297        -0.765137         0.272949   \n",
       "3                -2.873047        -3.654297        -0.765137         0.272949   \n",
       "4                -3.013672        -3.654297        -0.765137         0.272949   \n",
       "\n",
       "   mean_batch_25000  min_batch_25000_diff  max_batch_25000_diff  \\\n",
       "0         -2.683594             -0.895020              1.995117   \n",
       "1         -2.683594             -0.799316              2.089844   \n",
       "2         -2.683594             -1.248047              1.642578   \n",
       "3         -2.683594             -0.514648              2.375000   \n",
       "4         -2.683594             -0.502441              2.386719   \n",
       "\n",
       "   std_batch_25000_diff  mean_batch_25000_diff  signal_shift+1_batch_25000  \\\n",
       "0              3.033203               0.076233                    0.000000   \n",
       "1              3.128906               0.171997                   -2.759766   \n",
       "2              2.679688              -0.276367                   -2.855469   \n",
       "3              3.414062               0.456543                   -2.408203   \n",
       "4              3.425781               0.468750                   -3.140625   \n",
       "\n",
       "   signal_shift-1_batch_25000  signal_shift+2_batch_25000  \\\n",
       "0                   -2.855469                    0.000000   \n",
       "1                   -2.408203                    0.000000   \n",
       "2                   -3.140625                   -2.759766   \n",
       "3                   -3.152344                   -2.855469   \n",
       "4                   -2.642578                   -2.408203   \n",
       "\n",
       "   signal_shift-2_batch_25000  min_batch_slices2_25000  \\\n",
       "0                   -2.408203                -3.466797   \n",
       "1                   -3.140625                -3.466797   \n",
       "2                   -3.152344                -3.466797   \n",
       "3                   -2.642578                -3.466797   \n",
       "4                   -2.699219                -3.466797   \n",
       "\n",
       "   max_batch_slices2_25000  std_batch_slices2_25000  mean_batch_slices2_25000  \\\n",
       "0                 -1.90332                 0.244385                 -2.693359   \n",
       "1                 -1.90332                 0.244385                 -2.693359   \n",
       "2                 -1.90332                 0.244385                 -2.693359   \n",
       "3                 -1.90332                 0.244385                 -2.693359   \n",
       "4                 -1.90332                 0.244385                 -2.693359   \n",
       "\n",
       "   min_batch_slices2_25000_diff  max_batch_slices2_25000_diff  \\\n",
       "0                     -0.707031                      0.856934   \n",
       "1                     -0.611328                      0.952637   \n",
       "2                     -1.059570                      0.504395   \n",
       "3                     -0.326416                      1.237305   \n",
       "4                     -0.314453                      1.250000   \n",
       "\n",
       "   std_batch_slices2_25000_diff  mean_batch_slices2_25000_diff  \\\n",
       "0                      3.003906                       0.066223   \n",
       "1                      3.099609                       0.161987   \n",
       "2                      2.652344                      -0.286377   \n",
       "3                      3.384766                       0.446533   \n",
       "4                      3.396484                       0.458740   \n",
       "\n",
       "   signal_shift+1_batch_slices2_25000  signal_shift-1_batch_slices2_25000  \\\n",
       "0                            0.000000                           -2.855469   \n",
       "1                           -2.759766                           -2.408203   \n",
       "2                           -2.855469                           -3.140625   \n",
       "3                           -2.408203                           -3.152344   \n",
       "4                           -3.140625                           -2.642578   \n",
       "\n",
       "   signal_shift+2_batch_slices2_25000  signal_shift-2_batch_slices2_25000  \\\n",
       "0                            0.000000                           -2.408203   \n",
       "1                            0.000000                           -3.140625   \n",
       "2                           -2.759766                           -3.152344   \n",
       "3                           -2.855469                           -2.642578   \n",
       "4                           -2.408203                           -2.699219   \n",
       "\n",
       "   rolling_maen_1000_batch_25000  rolling_std_1000_batch_25000  \\\n",
       "0                            0.0                           0.0   \n",
       "1                            0.0                           0.0   \n",
       "2                            0.0                           0.0   \n",
       "3                            0.0                           0.0   \n",
       "4                            0.0                           0.0   \n",
       "\n",
       "   rolling_min_1000_batch_25000  rolling_max_1000_batch_25000  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   norm_1000_batch_25000  exp_Moving__1000_25000  \\\n",
       "0                    0.0               -2.759766   \n",
       "1                    0.0               -2.808594   \n",
       "2                    0.0               -2.607422   \n",
       "3                    0.0               -2.873047   \n",
       "4                    0.0               -3.013672   \n",
       "\n",
       "   rolling_maen_5000_batch_25000  rolling_std_5000_batch_25000  \\\n",
       "0                            0.0                           0.0   \n",
       "1                            0.0                           0.0   \n",
       "2                            0.0                           0.0   \n",
       "3                            0.0                           0.0   \n",
       "4                            0.0                           0.0   \n",
       "\n",
       "   rolling_min_5000_batch_25000  rolling_max_5000_batch_25000  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   norm_5000_batch_25000  exp_Moving__5000_25000  \\\n",
       "0                    0.0               -2.759766   \n",
       "1                    0.0               -2.808594   \n",
       "2                    0.0               -2.607422   \n",
       "3                    0.0               -2.873047   \n",
       "4                    0.0               -3.013672   \n",
       "\n",
       "   rolling_maen_10000_batch_25000  rolling_std_10000_batch_25000  \\\n",
       "0                             0.0                            0.0   \n",
       "1                             0.0                            0.0   \n",
       "2                             0.0                            0.0   \n",
       "3                             0.0                            0.0   \n",
       "4                             0.0                            0.0   \n",
       "\n",
       "   rolling_min_10000_batch_25000  rolling_max_10000_batch_25000  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                            0.0                            0.0   \n",
       "\n",
       "   norm_10000_batch_25000  exp_Moving__10000_25000  min_batch_50000  \\\n",
       "0                     0.0                -2.759766        -3.662109   \n",
       "1                     0.0                -2.808594        -3.662109   \n",
       "2                     0.0                -2.607422        -3.662109   \n",
       "3                     0.0                -2.873047        -3.662109   \n",
       "4                     0.0                -3.013672        -3.662109   \n",
       "\n",
       "   max_batch_50000  std_batch_50000  mean_batch_50000  min_batch_50000_diff  \\\n",
       "0        -0.765137         0.260742           -2.6875             -0.902344   \n",
       "1        -0.765137         0.260742           -2.6875             -0.806641   \n",
       "2        -0.765137         0.260742           -2.6875             -1.254883   \n",
       "3        -0.765137         0.260742           -2.6875             -0.521484   \n",
       "4        -0.765137         0.260742           -2.6875             -0.509766   \n",
       "\n",
       "   max_batch_50000_diff  std_batch_50000_diff  mean_batch_50000_diff  \\\n",
       "0              1.995117              3.021484               0.072815   \n",
       "1              2.089844              3.117188               0.168457   \n",
       "2              1.642578              2.667969              -0.279785   \n",
       "3              2.375000              3.400391               0.453125   \n",
       "4              2.386719              3.414062               0.465332   \n",
       "\n",
       "   signal_shift+1_batch_50000  signal_shift-1_batch_50000  \\\n",
       "0                    0.000000                   -2.855469   \n",
       "1                   -2.759766                   -2.408203   \n",
       "2                   -2.855469                   -3.140625   \n",
       "3                   -2.408203                   -3.152344   \n",
       "4                   -3.140625                   -2.642578   \n",
       "\n",
       "   signal_shift+2_batch_50000  signal_shift-2_batch_50000  \\\n",
       "0                    0.000000                   -2.408203   \n",
       "1                    0.000000                   -3.140625   \n",
       "2                   -2.759766                   -3.152344   \n",
       "3                   -2.855469                   -2.642578   \n",
       "4                   -2.408203                   -2.699219   \n",
       "\n",
       "   min_batch_slices2_50000  max_batch_slices2_50000  std_batch_slices2_50000  \\\n",
       "0                -3.589844                -1.862305                  0.24292   \n",
       "1                -3.589844                -1.862305                  0.24292   \n",
       "2                -3.589844                -1.862305                  0.24292   \n",
       "3                -3.589844                -1.862305                  0.24292   \n",
       "4                -3.589844                -1.862305                  0.24292   \n",
       "\n",
       "   mean_batch_slices2_50000  min_batch_slices2_50000_diff  \\\n",
       "0                 -2.695312                     -0.829590   \n",
       "1                 -2.695312                     -0.733887   \n",
       "2                 -2.695312                     -1.182617   \n",
       "3                 -2.695312                     -0.449219   \n",
       "4                 -2.695312                     -0.437012   \n",
       "\n",
       "   max_batch_slices2_50000_diff  std_batch_slices2_50000_diff  \\\n",
       "0                      0.897461                      3.003906   \n",
       "1                      0.993164                      3.099609   \n",
       "2                      0.544922                      2.650391   \n",
       "3                      1.277344                      3.382812   \n",
       "4                      1.290039                      3.394531   \n",
       "\n",
       "   mean_batch_slices2_50000_diff  signal_shift+1_batch_slices2_50000  \\\n",
       "0                       0.064392                            0.000000   \n",
       "1                       0.160034                           -2.759766   \n",
       "2                      -0.288330                           -2.855469   \n",
       "3                       0.444824                           -2.408203   \n",
       "4                       0.456787                           -3.140625   \n",
       "\n",
       "   signal_shift-1_batch_slices2_50000  signal_shift+2_batch_slices2_50000  \\\n",
       "0                           -2.855469                            0.000000   \n",
       "1                           -2.408203                            0.000000   \n",
       "2                           -3.140625                           -2.759766   \n",
       "3                           -3.152344                           -2.855469   \n",
       "4                           -2.642578                           -2.408203   \n",
       "\n",
       "   signal_shift-2_batch_slices2_50000  rolling_maen_1000_batch_50000  \\\n",
       "0                           -2.408203                            0.0   \n",
       "1                           -3.140625                            0.0   \n",
       "2                           -3.152344                            0.0   \n",
       "3                           -2.642578                            0.0   \n",
       "4                           -2.699219                            0.0   \n",
       "\n",
       "   rolling_std_1000_batch_50000  rolling_min_1000_batch_50000  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   rolling_max_1000_batch_50000  norm_1000_batch_50000  \\\n",
       "0                           0.0                    0.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    0.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   exp_Moving__1000_50000  rolling_maen_5000_batch_50000  \\\n",
       "0               -2.759766                            0.0   \n",
       "1               -2.808594                            0.0   \n",
       "2               -2.607422                            0.0   \n",
       "3               -2.873047                            0.0   \n",
       "4               -3.013672                            0.0   \n",
       "\n",
       "   rolling_std_5000_batch_50000  rolling_min_5000_batch_50000  \\\n",
       "0                           0.0                           0.0   \n",
       "1                           0.0                           0.0   \n",
       "2                           0.0                           0.0   \n",
       "3                           0.0                           0.0   \n",
       "4                           0.0                           0.0   \n",
       "\n",
       "   rolling_max_5000_batch_50000  norm_5000_batch_50000  \\\n",
       "0                           0.0                    0.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    0.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   exp_Moving__5000_50000  rolling_maen_10000_batch_50000  \\\n",
       "0               -2.759766                             0.0   \n",
       "1               -2.808594                             0.0   \n",
       "2               -2.607422                             0.0   \n",
       "3               -2.873047                             0.0   \n",
       "4               -3.013672                             0.0   \n",
       "\n",
       "   rolling_std_10000_batch_50000  rolling_min_10000_batch_50000  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                            0.0                            0.0   \n",
       "\n",
       "   rolling_max_10000_batch_50000  norm_10000_batch_50000  \\\n",
       "0                            0.0                     0.0   \n",
       "1                            0.0                     0.0   \n",
       "2                            0.0                     0.0   \n",
       "3                            0.0                     0.0   \n",
       "4                            0.0                     0.0   \n",
       "\n",
       "   exp_Moving__10000_50000  \n",
       "0                -2.759766  \n",
       "1                -2.808594  \n",
       "2                -2.607422  \n",
       "3                -2.873047  \n",
       "4                -3.013672  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_Metric(y_true, y_pred):\n",
    "    #labels = dtrain.get_label()\n",
    "    #print(preds.shape)\n",
    "    #print(preds)\n",
    "    y_pred = np.round(np.clip(y_pred, 0, 10)).astype(int)#np.argmax(y_pred, axis=0)\n",
    "    y_pred = np.array(y_pred).reshape(y_true.shape)\n",
    "#     score = metrics.cohen_kappa_score(labels, preds, weights = 'quadratic')\n",
    "    score = f1_score(y_true=y_true ,y_pred=y_pred, average='macro')\n",
    "    return ('KaggleMetric', score, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model(object):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True,ps={}):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.target = 'open_channels' #set your objective variable here\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "#         self.params = self.get_params()\n",
    "        self.params = self.set_params(ps)\n",
    "        self.y_pred, self.score, self.model = self.fit()\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    #split data x and y, and kfold\n",
    "    def get_cv(self):\n",
    "        #cv = GroupKFold(n_splits=self.n_splits)\n",
    "        cv = KFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        #cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        return cv.split(self.train_df, self.train_df[self.target])\n",
    "    \n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "        \n",
    "    def fit(self):\n",
    "        oof_pred = np.zeros((len(train_df), ))\n",
    "        y_pred = np.zeros((len(test_df), ))\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n",
    "            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model = self.train_model(train_set, val_set)\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(self.test_df[self.features])\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, lgb_Metric(y_val, oof_pred[val_idx])[1]))\n",
    "        _, loss_score, _ = lgb_Metric(self.train_df[self.target], oof_pred)\n",
    "        if self.verbose:\n",
    "            print('Our macroF1 is: ', loss_score)\n",
    "        return y_pred, loss_score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        x_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in x_train.columns]\n",
    "        x_val.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in x_val.columns]\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'n_estimators':10000,\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'regression',\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.75,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'feature_fraction': 0.9,\n",
    "                    'max_depth': 15,\n",
    "                    'lambda_l1': 1,  \n",
    "                    'lambda_l2': 1,\n",
    "                    'early_stopping_rounds': 100\n",
    "                    }\n",
    "        return params\n",
    "    def set_params(self,ps={}):\n",
    "        params = self.get_params()\n",
    "        if 'subsample_freq' in ps:\n",
    "            params['subsample_freq']=int(ps['subsample_freq'])\n",
    "            params['learning_rate']=ps['learning_rate']\n",
    "            params['feature_fraction']=ps['feature_fraction']\n",
    "            params['lambda_l1']=ps['lambda_l1']\n",
    "            params['lambda_l2']=ps['lambda_l2']\n",
    "            params['max_depth']=int(ps['max_depth'])\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train\n",
    "test_df=test\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = [] #In this time, there were no categorical feature\n",
    "features = test_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.997173\tvalid_1's rmse: 0.996849\n",
      "[200]\ttraining's rmse: 0.4105\tvalid_1's rmse: 0.410089\n",
      "[300]\ttraining's rmse: 0.234325\tvalid_1's rmse: 0.233764\n",
      "[400]\ttraining's rmse: 0.194087\tvalid_1's rmse: 0.193535\n",
      "[500]\ttraining's rmse: 0.184897\tvalid_1's rmse: 0.184459\n",
      "[600]\ttraining's rmse: 0.181587\tvalid_1's rmse: 0.18125\n",
      "[700]\ttraining's rmse: 0.179724\tvalid_1's rmse: 0.179463\n",
      "[800]\ttraining's rmse: 0.178352\tvalid_1's rmse: 0.178156\n",
      "[900]\ttraining's rmse: 0.177144\tvalid_1's rmse: 0.177009\n",
      "[1000]\ttraining's rmse: 0.176118\tvalid_1's rmse: 0.17606\n",
      "[1100]\ttraining's rmse: 0.17522\tvalid_1's rmse: 0.175222\n",
      "[1200]\ttraining's rmse: 0.174442\tvalid_1's rmse: 0.174504\n",
      "[1300]\ttraining's rmse: 0.173717\tvalid_1's rmse: 0.173842\n",
      "[1400]\ttraining's rmse: 0.173045\tvalid_1's rmse: 0.173236\n",
      "[1500]\ttraining's rmse: 0.172426\tvalid_1's rmse: 0.172678\n",
      "[1600]\ttraining's rmse: 0.171879\tvalid_1's rmse: 0.17219\n",
      "[1700]\ttraining's rmse: 0.171344\tvalid_1's rmse: 0.171709\n",
      "[1800]\ttraining's rmse: 0.170839\tvalid_1's rmse: 0.171262\n",
      "[1900]\ttraining's rmse: 0.170375\tvalid_1's rmse: 0.170854\n",
      "[2000]\ttraining's rmse: 0.169962\tvalid_1's rmse: 0.170497\n",
      "[2100]\ttraining's rmse: 0.16959\tvalid_1's rmse: 0.170182\n",
      "[2200]\ttraining's rmse: 0.169246\tvalid_1's rmse: 0.169897\n",
      "[2300]\ttraining's rmse: 0.168913\tvalid_1's rmse: 0.169617\n",
      "[2400]\ttraining's rmse: 0.168571\tvalid_1's rmse: 0.169329\n",
      "[2500]\ttraining's rmse: 0.16824\tvalid_1's rmse: 0.169051\n",
      "[2600]\ttraining's rmse: 0.167938\tvalid_1's rmse: 0.168801\n",
      "[2700]\ttraining's rmse: 0.167647\tvalid_1's rmse: 0.16856\n",
      "[2800]\ttraining's rmse: 0.167389\tvalid_1's rmse: 0.168349\n",
      "[2900]\ttraining's rmse: 0.167122\tvalid_1's rmse: 0.168131\n",
      "[3000]\ttraining's rmse: 0.16688\tvalid_1's rmse: 0.167942\n",
      "[3100]\ttraining's rmse: 0.166654\tvalid_1's rmse: 0.167769\n",
      "[3200]\ttraining's rmse: 0.166428\tvalid_1's rmse: 0.167592\n",
      "[3300]\ttraining's rmse: 0.166202\tvalid_1's rmse: 0.167412\n",
      "[3400]\ttraining's rmse: 0.165996\tvalid_1's rmse: 0.167252\n",
      "[3500]\ttraining's rmse: 0.165812\tvalid_1's rmse: 0.167117\n",
      "[3600]\ttraining's rmse: 0.165597\tvalid_1's rmse: 0.166948\n",
      "[3700]\ttraining's rmse: 0.165402\tvalid_1's rmse: 0.166801\n",
      "[3800]\ttraining's rmse: 0.165215\tvalid_1's rmse: 0.16666\n",
      "[3900]\ttraining's rmse: 0.165029\tvalid_1's rmse: 0.166523\n",
      "[4000]\ttraining's rmse: 0.164868\tvalid_1's rmse: 0.166412\n",
      "[4100]\ttraining's rmse: 0.164696\tvalid_1's rmse: 0.166286\n",
      "[4200]\ttraining's rmse: 0.164518\tvalid_1's rmse: 0.166155\n",
      "[4300]\ttraining's rmse: 0.164357\tvalid_1's rmse: 0.166039\n",
      "[4400]\ttraining's rmse: 0.164209\tvalid_1's rmse: 0.165941\n",
      "[4500]\ttraining's rmse: 0.164041\tvalid_1's rmse: 0.165817\n",
      "[4600]\ttraining's rmse: 0.163899\tvalid_1's rmse: 0.165722\n",
      "[4700]\ttraining's rmse: 0.163767\tvalid_1's rmse: 0.165637\n",
      "[4800]\ttraining's rmse: 0.163622\tvalid_1's rmse: 0.165539\n",
      "[4900]\ttraining's rmse: 0.163484\tvalid_1's rmse: 0.16545\n",
      "[5000]\ttraining's rmse: 0.163358\tvalid_1's rmse: 0.16537\n",
      "[5100]\ttraining's rmse: 0.16322\tvalid_1's rmse: 0.16528\n",
      "[5200]\ttraining's rmse: 0.163082\tvalid_1's rmse: 0.165188\n",
      "[5300]\ttraining's rmse: 0.162961\tvalid_1's rmse: 0.16511\n",
      "[5400]\ttraining's rmse: 0.162845\tvalid_1's rmse: 0.165039\n",
      "[5500]\ttraining's rmse: 0.162717\tvalid_1's rmse: 0.164958\n",
      "[5600]\ttraining's rmse: 0.162605\tvalid_1's rmse: 0.164894\n",
      "[5700]\ttraining's rmse: 0.162497\tvalid_1's rmse: 0.164832\n",
      "[5800]\ttraining's rmse: 0.162383\tvalid_1's rmse: 0.164762\n",
      "[5900]\ttraining's rmse: 0.162275\tvalid_1's rmse: 0.164701\n",
      "[6000]\ttraining's rmse: 0.162156\tvalid_1's rmse: 0.164628\n",
      "[6100]\ttraining's rmse: 0.162047\tvalid_1's rmse: 0.164567\n",
      "[6200]\ttraining's rmse: 0.161941\tvalid_1's rmse: 0.164506\n",
      "[6300]\ttraining's rmse: 0.161835\tvalid_1's rmse: 0.164449\n",
      "[6400]\ttraining's rmse: 0.161734\tvalid_1's rmse: 0.164391\n",
      "[6500]\ttraining's rmse: 0.161629\tvalid_1's rmse: 0.164331\n",
      "[6600]\ttraining's rmse: 0.161533\tvalid_1's rmse: 0.164283\n",
      "[6700]\ttraining's rmse: 0.161422\tvalid_1's rmse: 0.164216\n",
      "[6800]\ttraining's rmse: 0.161328\tvalid_1's rmse: 0.164167\n",
      "[6900]\ttraining's rmse: 0.161237\tvalid_1's rmse: 0.164118\n",
      "[7000]\ttraining's rmse: 0.161144\tvalid_1's rmse: 0.164071\n",
      "[7100]\ttraining's rmse: 0.161053\tvalid_1's rmse: 0.164022\n",
      "[7200]\ttraining's rmse: 0.160967\tvalid_1's rmse: 0.163979\n",
      "[7300]\ttraining's rmse: 0.160877\tvalid_1's rmse: 0.163932\n",
      "[7400]\ttraining's rmse: 0.160789\tvalid_1's rmse: 0.163889\n",
      "[7500]\ttraining's rmse: 0.160697\tvalid_1's rmse: 0.163842\n",
      "[7600]\ttraining's rmse: 0.160613\tvalid_1's rmse: 0.1638\n",
      "[7700]\ttraining's rmse: 0.160526\tvalid_1's rmse: 0.163754\n",
      "[7800]\ttraining's rmse: 0.160445\tvalid_1's rmse: 0.163716\n",
      "[7900]\ttraining's rmse: 0.160364\tvalid_1's rmse: 0.163678\n",
      "[8000]\ttraining's rmse: 0.160281\tvalid_1's rmse: 0.163639\n",
      "[8100]\ttraining's rmse: 0.160199\tvalid_1's rmse: 0.163599\n",
      "[8200]\ttraining's rmse: 0.160116\tvalid_1's rmse: 0.163563\n",
      "[8300]\ttraining's rmse: 0.160038\tvalid_1's rmse: 0.163528\n",
      "[8400]\ttraining's rmse: 0.159951\tvalid_1's rmse: 0.163483\n",
      "[8500]\ttraining's rmse: 0.159873\tvalid_1's rmse: 0.163448\n",
      "[8600]\ttraining's rmse: 0.159794\tvalid_1's rmse: 0.163412\n",
      "[8700]\ttraining's rmse: 0.159719\tvalid_1's rmse: 0.163378\n",
      "[8800]\ttraining's rmse: 0.159639\tvalid_1's rmse: 0.163341\n",
      "[8900]\ttraining's rmse: 0.159572\tvalid_1's rmse: 0.163315\n",
      "[9000]\ttraining's rmse: 0.15949\tvalid_1's rmse: 0.163274\n",
      "[9100]\ttraining's rmse: 0.159419\tvalid_1's rmse: 0.163245\n",
      "[9200]\ttraining's rmse: 0.159339\tvalid_1's rmse: 0.163208\n",
      "[9300]\ttraining's rmse: 0.159269\tvalid_1's rmse: 0.163179\n",
      "[9400]\ttraining's rmse: 0.159192\tvalid_1's rmse: 0.16314\n",
      "[9500]\ttraining's rmse: 0.159115\tvalid_1's rmse: 0.163106\n",
      "[9600]\ttraining's rmse: 0.15904\tvalid_1's rmse: 0.163072\n",
      "[9700]\ttraining's rmse: 0.158972\tvalid_1's rmse: 0.163046\n",
      "[9800]\ttraining's rmse: 0.158903\tvalid_1's rmse: 0.163018\n",
      "[9900]\ttraining's rmse: 0.158828\tvalid_1's rmse: 0.162984\n",
      "[10000]\ttraining's rmse: 0.158753\tvalid_1's rmse: 0.162945\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's rmse: 0.158753\tvalid_1's rmse: 0.162945\n",
      "Partial score of fold 0 is: 0.9352207836375901\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.997013\tvalid_1's rmse: 0.997209\n",
      "[200]\ttraining's rmse: 0.410336\tvalid_1's rmse: 0.410477\n",
      "[300]\ttraining's rmse: 0.234108\tvalid_1's rmse: 0.234585\n",
      "[400]\ttraining's rmse: 0.193786\tvalid_1's rmse: 0.194518\n",
      "[500]\ttraining's rmse: 0.184702\tvalid_1's rmse: 0.185518\n",
      "[600]\ttraining's rmse: 0.181389\tvalid_1's rmse: 0.182252\n",
      "[700]\ttraining's rmse: 0.17953\tvalid_1's rmse: 0.180418\n",
      "[800]\ttraining's rmse: 0.178143\tvalid_1's rmse: 0.179069\n",
      "[900]\ttraining's rmse: 0.176957\tvalid_1's rmse: 0.177908\n",
      "[1000]\ttraining's rmse: 0.175923\tvalid_1's rmse: 0.176896\n",
      "[1100]\ttraining's rmse: 0.175055\tvalid_1's rmse: 0.176057\n",
      "[1200]\ttraining's rmse: 0.174277\tvalid_1's rmse: 0.175304\n",
      "[1300]\ttraining's rmse: 0.173551\tvalid_1's rmse: 0.174605\n",
      "[1400]\ttraining's rmse: 0.172925\tvalid_1's rmse: 0.174009\n",
      "[1500]\ttraining's rmse: 0.172331\tvalid_1's rmse: 0.173447\n",
      "[1600]\ttraining's rmse: 0.171802\tvalid_1's rmse: 0.172955\n",
      "[1700]\ttraining's rmse: 0.171303\tvalid_1's rmse: 0.172492\n",
      "[1800]\ttraining's rmse: 0.170805\tvalid_1's rmse: 0.172024\n",
      "[1900]\ttraining's rmse: 0.17038\tvalid_1's rmse: 0.171633\n",
      "[2000]\ttraining's rmse: 0.169977\tvalid_1's rmse: 0.171261\n",
      "[2100]\ttraining's rmse: 0.169602\tvalid_1's rmse: 0.170925\n",
      "[2200]\ttraining's rmse: 0.169237\tvalid_1's rmse: 0.170593\n",
      "[2300]\ttraining's rmse: 0.168879\tvalid_1's rmse: 0.170268\n",
      "[2400]\ttraining's rmse: 0.168529\tvalid_1's rmse: 0.169952\n",
      "[2500]\ttraining's rmse: 0.168235\tvalid_1's rmse: 0.169699\n",
      "[2600]\ttraining's rmse: 0.167932\tvalid_1's rmse: 0.169433\n",
      "[2700]\ttraining's rmse: 0.167661\tvalid_1's rmse: 0.169205\n",
      "[2800]\ttraining's rmse: 0.167377\tvalid_1's rmse: 0.168957\n",
      "[2900]\ttraining's rmse: 0.167121\tvalid_1's rmse: 0.168745\n",
      "[3000]\ttraining's rmse: 0.166883\tvalid_1's rmse: 0.168549\n",
      "[3100]\ttraining's rmse: 0.166639\tvalid_1's rmse: 0.168347\n",
      "[3200]\ttraining's rmse: 0.166421\tvalid_1's rmse: 0.168169\n",
      "[3300]\ttraining's rmse: 0.16621\tvalid_1's rmse: 0.168001\n",
      "[3400]\ttraining's rmse: 0.166001\tvalid_1's rmse: 0.167836\n",
      "[3500]\ttraining's rmse: 0.165802\tvalid_1's rmse: 0.167684\n",
      "[3600]\ttraining's rmse: 0.165576\tvalid_1's rmse: 0.1675\n",
      "[3700]\ttraining's rmse: 0.165383\tvalid_1's rmse: 0.167349\n",
      "[3800]\ttraining's rmse: 0.165204\tvalid_1's rmse: 0.167212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3900]\ttraining's rmse: 0.165021\tvalid_1's rmse: 0.16707\n",
      "[4000]\ttraining's rmse: 0.164846\tvalid_1's rmse: 0.166936\n",
      "[4100]\ttraining's rmse: 0.164693\tvalid_1's rmse: 0.166827\n",
      "[4200]\ttraining's rmse: 0.164512\tvalid_1's rmse: 0.16669\n",
      "[4300]\ttraining's rmse: 0.164356\tvalid_1's rmse: 0.166575\n",
      "[4400]\ttraining's rmse: 0.164205\tvalid_1's rmse: 0.16647\n",
      "[4500]\ttraining's rmse: 0.164057\tvalid_1's rmse: 0.166364\n",
      "[4600]\ttraining's rmse: 0.163909\tvalid_1's rmse: 0.166262\n",
      "[4700]\ttraining's rmse: 0.163761\tvalid_1's rmse: 0.166158\n",
      "[4800]\ttraining's rmse: 0.163621\tvalid_1's rmse: 0.166061\n",
      "[4900]\ttraining's rmse: 0.163478\tvalid_1's rmse: 0.16596\n",
      "[5000]\ttraining's rmse: 0.163332\tvalid_1's rmse: 0.165856\n",
      "[5100]\ttraining's rmse: 0.163207\tvalid_1's rmse: 0.165772\n",
      "[5200]\ttraining's rmse: 0.16308\tvalid_1's rmse: 0.16569\n",
      "[5300]\ttraining's rmse: 0.162954\tvalid_1's rmse: 0.165605\n",
      "[5400]\ttraining's rmse: 0.162822\tvalid_1's rmse: 0.165515\n",
      "[5500]\ttraining's rmse: 0.162696\tvalid_1's rmse: 0.16543\n",
      "[5600]\ttraining's rmse: 0.162567\tvalid_1's rmse: 0.165338\n",
      "[5700]\ttraining's rmse: 0.16245\tvalid_1's rmse: 0.165262\n",
      "[5800]\ttraining's rmse: 0.162329\tvalid_1's rmse: 0.16518\n",
      "[5900]\ttraining's rmse: 0.162202\tvalid_1's rmse: 0.165095\n",
      "[6000]\ttraining's rmse: 0.162095\tvalid_1's rmse: 0.165029\n",
      "[6100]\ttraining's rmse: 0.161981\tvalid_1's rmse: 0.164958\n",
      "[6200]\ttraining's rmse: 0.16187\tvalid_1's rmse: 0.164889\n",
      "[6300]\ttraining's rmse: 0.161756\tvalid_1's rmse: 0.164815\n",
      "[6400]\ttraining's rmse: 0.161659\tvalid_1's rmse: 0.164763\n",
      "[6500]\ttraining's rmse: 0.161553\tvalid_1's rmse: 0.164698\n",
      "[6600]\ttraining's rmse: 0.161456\tvalid_1's rmse: 0.164643\n",
      "[6700]\ttraining's rmse: 0.161356\tvalid_1's rmse: 0.164589\n",
      "[6800]\ttraining's rmse: 0.161261\tvalid_1's rmse: 0.164535\n",
      "[6900]\ttraining's rmse: 0.161163\tvalid_1's rmse: 0.164479\n",
      "[7000]\ttraining's rmse: 0.161069\tvalid_1's rmse: 0.164426\n",
      "[7100]\ttraining's rmse: 0.160975\tvalid_1's rmse: 0.164374\n",
      "[7200]\ttraining's rmse: 0.160874\tvalid_1's rmse: 0.164313\n",
      "[7300]\ttraining's rmse: 0.160783\tvalid_1's rmse: 0.164265\n",
      "[7400]\ttraining's rmse: 0.160709\tvalid_1's rmse: 0.164231\n",
      "[7500]\ttraining's rmse: 0.160625\tvalid_1's rmse: 0.164185\n",
      "[7600]\ttraining's rmse: 0.160539\tvalid_1's rmse: 0.164139\n",
      "[7700]\ttraining's rmse: 0.160447\tvalid_1's rmse: 0.164089\n",
      "[7800]\ttraining's rmse: 0.160364\tvalid_1's rmse: 0.164047\n",
      "[7900]\ttraining's rmse: 0.160285\tvalid_1's rmse: 0.164012\n",
      "[8000]\ttraining's rmse: 0.160207\tvalid_1's rmse: 0.163977\n",
      "[8100]\ttraining's rmse: 0.160124\tvalid_1's rmse: 0.163935\n",
      "[8200]\ttraining's rmse: 0.160045\tvalid_1's rmse: 0.163899\n",
      "[8300]\ttraining's rmse: 0.159971\tvalid_1's rmse: 0.163868\n",
      "[8400]\ttraining's rmse: 0.159891\tvalid_1's rmse: 0.163828\n",
      "[8500]\ttraining's rmse: 0.159815\tvalid_1's rmse: 0.163793\n",
      "[8600]\ttraining's rmse: 0.159737\tvalid_1's rmse: 0.163753\n",
      "[8700]\ttraining's rmse: 0.15966\tvalid_1's rmse: 0.163716\n",
      "[8800]\ttraining's rmse: 0.159585\tvalid_1's rmse: 0.163684\n",
      "[8900]\ttraining's rmse: 0.159512\tvalid_1's rmse: 0.163652\n",
      "[9000]\ttraining's rmse: 0.159439\tvalid_1's rmse: 0.163618\n",
      "[9100]\ttraining's rmse: 0.159364\tvalid_1's rmse: 0.163587\n",
      "[9200]\ttraining's rmse: 0.159286\tvalid_1's rmse: 0.163552\n",
      "[9300]\ttraining's rmse: 0.159215\tvalid_1's rmse: 0.163523\n",
      "[9400]\ttraining's rmse: 0.159145\tvalid_1's rmse: 0.16349\n",
      "[9500]\ttraining's rmse: 0.15908\tvalid_1's rmse: 0.163464\n",
      "[9600]\ttraining's rmse: 0.159003\tvalid_1's rmse: 0.163427\n",
      "[9700]\ttraining's rmse: 0.158927\tvalid_1's rmse: 0.163393\n",
      "[9800]\ttraining's rmse: 0.158863\tvalid_1's rmse: 0.163366\n",
      "[9900]\ttraining's rmse: 0.158798\tvalid_1's rmse: 0.163343\n",
      "[10000]\ttraining's rmse: 0.158733\tvalid_1's rmse: 0.163318\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's rmse: 0.158733\tvalid_1's rmse: 0.163318\n",
      "Partial score of fold 1 is: 0.9347310096039874\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.996866\tvalid_1's rmse: 0.998041\n",
      "[200]\ttraining's rmse: 0.410306\tvalid_1's rmse: 0.411097\n",
      "[300]\ttraining's rmse: 0.234165\tvalid_1's rmse: 0.234877\n",
      "[400]\ttraining's rmse: 0.193863\tvalid_1's rmse: 0.194556\n",
      "[500]\ttraining's rmse: 0.184657\tvalid_1's rmse: 0.185369\n",
      "[600]\ttraining's rmse: 0.181346\tvalid_1's rmse: 0.182103\n",
      "[700]\ttraining's rmse: 0.179472\tvalid_1's rmse: 0.180281\n",
      "[800]\ttraining's rmse: 0.178111\tvalid_1's rmse: 0.17897\n",
      "[900]\ttraining's rmse: 0.17697\tvalid_1's rmse: 0.177873\n",
      "[1000]\ttraining's rmse: 0.175929\tvalid_1's rmse: 0.176876\n",
      "[1100]\ttraining's rmse: 0.175019\tvalid_1's rmse: 0.176007\n",
      "[1200]\ttraining's rmse: 0.174256\tvalid_1's rmse: 0.175288\n",
      "[1300]\ttraining's rmse: 0.173544\tvalid_1's rmse: 0.174628\n",
      "[1400]\ttraining's rmse: 0.172936\tvalid_1's rmse: 0.174069\n",
      "[1500]\ttraining's rmse: 0.172348\tvalid_1's rmse: 0.173529\n",
      "[1600]\ttraining's rmse: 0.171799\tvalid_1's rmse: 0.173025\n",
      "[1700]\ttraining's rmse: 0.171235\tvalid_1's rmse: 0.172511\n",
      "[1800]\ttraining's rmse: 0.170768\tvalid_1's rmse: 0.172092\n",
      "[1900]\ttraining's rmse: 0.170336\tvalid_1's rmse: 0.171711\n",
      "[2000]\ttraining's rmse: 0.169919\tvalid_1's rmse: 0.171334\n",
      "[2100]\ttraining's rmse: 0.169541\tvalid_1's rmse: 0.170999\n",
      "[2200]\ttraining's rmse: 0.169182\tvalid_1's rmse: 0.170685\n",
      "[2300]\ttraining's rmse: 0.168817\tvalid_1's rmse: 0.170368\n",
      "[2400]\ttraining's rmse: 0.168478\tvalid_1's rmse: 0.170076\n",
      "[2500]\ttraining's rmse: 0.168131\tvalid_1's rmse: 0.169779\n",
      "[2600]\ttraining's rmse: 0.167805\tvalid_1's rmse: 0.169499\n",
      "[2700]\ttraining's rmse: 0.167543\tvalid_1's rmse: 0.169282\n",
      "[2800]\ttraining's rmse: 0.167265\tvalid_1's rmse: 0.169048\n",
      "[2900]\ttraining's rmse: 0.167005\tvalid_1's rmse: 0.168828\n",
      "[3000]\ttraining's rmse: 0.166742\tvalid_1's rmse: 0.168612\n",
      "[3100]\ttraining's rmse: 0.166502\tvalid_1's rmse: 0.16842\n",
      "[3200]\ttraining's rmse: 0.166267\tvalid_1's rmse: 0.168229\n",
      "[3300]\ttraining's rmse: 0.166065\tvalid_1's rmse: 0.168077\n",
      "[3400]\ttraining's rmse: 0.165854\tvalid_1's rmse: 0.167912\n",
      "[3500]\ttraining's rmse: 0.165649\tvalid_1's rmse: 0.167754\n",
      "[3600]\ttraining's rmse: 0.165447\tvalid_1's rmse: 0.167597\n",
      "[3700]\ttraining's rmse: 0.165249\tvalid_1's rmse: 0.167445\n",
      "[3800]\ttraining's rmse: 0.165072\tvalid_1's rmse: 0.16731\n",
      "[3900]\ttraining's rmse: 0.164894\tvalid_1's rmse: 0.167179\n",
      "[4000]\ttraining's rmse: 0.164715\tvalid_1's rmse: 0.167048\n",
      "[4100]\ttraining's rmse: 0.164527\tvalid_1's rmse: 0.166907\n",
      "[4200]\ttraining's rmse: 0.164365\tvalid_1's rmse: 0.166792\n",
      "[4300]\ttraining's rmse: 0.164215\tvalid_1's rmse: 0.166689\n",
      "[4400]\ttraining's rmse: 0.16406\tvalid_1's rmse: 0.166578\n",
      "[4500]\ttraining's rmse: 0.163905\tvalid_1's rmse: 0.16647\n",
      "[4600]\ttraining's rmse: 0.16376\tvalid_1's rmse: 0.166371\n",
      "[4700]\ttraining's rmse: 0.163628\tvalid_1's rmse: 0.166286\n",
      "[4800]\ttraining's rmse: 0.163485\tvalid_1's rmse: 0.166186\n",
      "[4900]\ttraining's rmse: 0.163338\tvalid_1's rmse: 0.166084\n",
      "[5000]\ttraining's rmse: 0.163189\tvalid_1's rmse: 0.16598\n",
      "[5100]\ttraining's rmse: 0.163063\tvalid_1's rmse: 0.165897\n",
      "[5200]\ttraining's rmse: 0.162934\tvalid_1's rmse: 0.165812\n",
      "[5300]\ttraining's rmse: 0.162804\tvalid_1's rmse: 0.165727\n",
      "[5400]\ttraining's rmse: 0.162682\tvalid_1's rmse: 0.165646\n",
      "[5500]\ttraining's rmse: 0.162563\tvalid_1's rmse: 0.165574\n",
      "[5600]\ttraining's rmse: 0.162443\tvalid_1's rmse: 0.1655\n",
      "[5700]\ttraining's rmse: 0.162323\tvalid_1's rmse: 0.165423\n",
      "[5800]\ttraining's rmse: 0.162204\tvalid_1's rmse: 0.165348\n",
      "[5900]\ttraining's rmse: 0.162098\tvalid_1's rmse: 0.165287\n",
      "[6000]\ttraining's rmse: 0.161981\tvalid_1's rmse: 0.165215\n",
      "[6100]\ttraining's rmse: 0.161871\tvalid_1's rmse: 0.165149\n",
      "[6200]\ttraining's rmse: 0.161766\tvalid_1's rmse: 0.165089\n",
      "[6300]\ttraining's rmse: 0.161657\tvalid_1's rmse: 0.165024\n",
      "[6400]\ttraining's rmse: 0.161545\tvalid_1's rmse: 0.164956\n",
      "[6500]\ttraining's rmse: 0.161444\tvalid_1's rmse: 0.164898\n",
      "[6600]\ttraining's rmse: 0.161342\tvalid_1's rmse: 0.164841\n",
      "[6700]\ttraining's rmse: 0.161242\tvalid_1's rmse: 0.164785\n",
      "[6800]\ttraining's rmse: 0.161129\tvalid_1's rmse: 0.164714\n",
      "[6900]\ttraining's rmse: 0.161038\tvalid_1's rmse: 0.164665\n",
      "[7000]\ttraining's rmse: 0.160938\tvalid_1's rmse: 0.164609\n",
      "[7100]\ttraining's rmse: 0.160841\tvalid_1's rmse: 0.164554\n",
      "[7200]\ttraining's rmse: 0.160754\tvalid_1's rmse: 0.164509\n",
      "[7300]\ttraining's rmse: 0.160659\tvalid_1's rmse: 0.164456\n",
      "[7400]\ttraining's rmse: 0.160573\tvalid_1's rmse: 0.164414\n",
      "[7500]\ttraining's rmse: 0.16048\tvalid_1's rmse: 0.164365\n",
      "[7600]\ttraining's rmse: 0.160398\tvalid_1's rmse: 0.164325\n",
      "[7700]\ttraining's rmse: 0.16031\tvalid_1's rmse: 0.164278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7800]\ttraining's rmse: 0.160227\tvalid_1's rmse: 0.164238\n",
      "[7900]\ttraining's rmse: 0.160141\tvalid_1's rmse: 0.164196\n",
      "[8000]\ttraining's rmse: 0.160057\tvalid_1's rmse: 0.164154\n",
      "[8100]\ttraining's rmse: 0.15998\tvalid_1's rmse: 0.164118\n",
      "[8200]\ttraining's rmse: 0.159893\tvalid_1's rmse: 0.164072\n",
      "[8300]\ttraining's rmse: 0.159806\tvalid_1's rmse: 0.164025\n",
      "[8400]\ttraining's rmse: 0.159721\tvalid_1's rmse: 0.163982\n",
      "[8500]\ttraining's rmse: 0.159646\tvalid_1's rmse: 0.163947\n",
      "[8600]\ttraining's rmse: 0.159568\tvalid_1's rmse: 0.163912\n",
      "[8700]\ttraining's rmse: 0.159497\tvalid_1's rmse: 0.163881\n",
      "[8800]\ttraining's rmse: 0.159428\tvalid_1's rmse: 0.163853\n",
      "[8900]\ttraining's rmse: 0.159357\tvalid_1's rmse: 0.163819\n",
      "[9000]\ttraining's rmse: 0.159288\tvalid_1's rmse: 0.163791\n",
      "[9100]\ttraining's rmse: 0.159211\tvalid_1's rmse: 0.163751\n",
      "[9200]\ttraining's rmse: 0.159139\tvalid_1's rmse: 0.163718\n",
      "[9300]\ttraining's rmse: 0.159065\tvalid_1's rmse: 0.163685\n",
      "[9400]\ttraining's rmse: 0.158988\tvalid_1's rmse: 0.163647\n",
      "[9500]\ttraining's rmse: 0.15892\tvalid_1's rmse: 0.16362\n",
      "[9600]\ttraining's rmse: 0.158848\tvalid_1's rmse: 0.163588\n",
      "[9700]\ttraining's rmse: 0.158773\tvalid_1's rmse: 0.163554\n",
      "[9800]\ttraining's rmse: 0.158707\tvalid_1's rmse: 0.163529\n",
      "[9900]\ttraining's rmse: 0.158643\tvalid_1's rmse: 0.163507\n",
      "[10000]\ttraining's rmse: 0.158575\tvalid_1's rmse: 0.163479\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's rmse: 0.158575\tvalid_1's rmse: 0.163479\n",
      "Partial score of fold 2 is: 0.9349198032544329\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.997182\tvalid_1's rmse: 0.996985\n",
      "[200]\ttraining's rmse: 0.410524\tvalid_1's rmse: 0.410398\n",
      "[300]\ttraining's rmse: 0.234326\tvalid_1's rmse: 0.234002\n",
      "[400]\ttraining's rmse: 0.194023\tvalid_1's rmse: 0.19364\n",
      "[500]\ttraining's rmse: 0.184829\tvalid_1's rmse: 0.184471\n",
      "[600]\ttraining's rmse: 0.181534\tvalid_1's rmse: 0.181207\n",
      "[700]\ttraining's rmse: 0.179707\tvalid_1's rmse: 0.179415\n",
      "[800]\ttraining's rmse: 0.178328\tvalid_1's rmse: 0.178058\n",
      "[900]\ttraining's rmse: 0.177135\tvalid_1's rmse: 0.176903\n",
      "[1000]\ttraining's rmse: 0.17612\tvalid_1's rmse: 0.175931\n",
      "[1100]\ttraining's rmse: 0.175259\tvalid_1's rmse: 0.175114\n",
      "[1200]\ttraining's rmse: 0.174483\tvalid_1's rmse: 0.174379\n",
      "[1300]\ttraining's rmse: 0.173788\tvalid_1's rmse: 0.173721\n",
      "[1400]\ttraining's rmse: 0.173119\tvalid_1's rmse: 0.173094\n",
      "[1500]\ttraining's rmse: 0.172481\tvalid_1's rmse: 0.172494\n",
      "[1600]\ttraining's rmse: 0.171904\tvalid_1's rmse: 0.171955\n",
      "[1700]\ttraining's rmse: 0.171355\tvalid_1's rmse: 0.17145\n",
      "[1800]\ttraining's rmse: 0.170919\tvalid_1's rmse: 0.171062\n",
      "[1900]\ttraining's rmse: 0.170476\tvalid_1's rmse: 0.170666\n",
      "[2000]\ttraining's rmse: 0.170056\tvalid_1's rmse: 0.170291\n",
      "[2100]\ttraining's rmse: 0.169656\tvalid_1's rmse: 0.169939\n",
      "[2200]\ttraining's rmse: 0.169298\tvalid_1's rmse: 0.16963\n",
      "[2300]\ttraining's rmse: 0.168946\tvalid_1's rmse: 0.169329\n",
      "[2400]\ttraining's rmse: 0.168606\tvalid_1's rmse: 0.169037\n",
      "[2500]\ttraining's rmse: 0.168296\tvalid_1's rmse: 0.168774\n",
      "[2600]\ttraining's rmse: 0.168022\tvalid_1's rmse: 0.168548\n",
      "[2700]\ttraining's rmse: 0.167728\tvalid_1's rmse: 0.168303\n",
      "[2800]\ttraining's rmse: 0.167457\tvalid_1's rmse: 0.168078\n",
      "[2900]\ttraining's rmse: 0.167186\tvalid_1's rmse: 0.167854\n",
      "[3000]\ttraining's rmse: 0.166944\tvalid_1's rmse: 0.167654\n",
      "[3100]\ttraining's rmse: 0.166694\tvalid_1's rmse: 0.167451\n",
      "[3200]\ttraining's rmse: 0.166481\tvalid_1's rmse: 0.16728\n",
      "[3300]\ttraining's rmse: 0.166253\tvalid_1's rmse: 0.167098\n",
      "[3400]\ttraining's rmse: 0.166055\tvalid_1's rmse: 0.166946\n",
      "[3500]\ttraining's rmse: 0.165847\tvalid_1's rmse: 0.166787\n",
      "[3600]\ttraining's rmse: 0.165647\tvalid_1's rmse: 0.166633\n",
      "[3700]\ttraining's rmse: 0.165447\tvalid_1's rmse: 0.166476\n",
      "[3800]\ttraining's rmse: 0.165248\tvalid_1's rmse: 0.166323\n",
      "[3900]\ttraining's rmse: 0.165081\tvalid_1's rmse: 0.166203\n",
      "[4000]\ttraining's rmse: 0.164916\tvalid_1's rmse: 0.166084\n",
      "[4100]\ttraining's rmse: 0.164749\tvalid_1's rmse: 0.165962\n",
      "[4200]\ttraining's rmse: 0.164582\tvalid_1's rmse: 0.165836\n",
      "[4300]\ttraining's rmse: 0.164417\tvalid_1's rmse: 0.165718\n",
      "[4400]\ttraining's rmse: 0.164263\tvalid_1's rmse: 0.165608\n",
      "[4500]\ttraining's rmse: 0.164115\tvalid_1's rmse: 0.165503\n",
      "[4600]\ttraining's rmse: 0.163964\tvalid_1's rmse: 0.165393\n",
      "[4700]\ttraining's rmse: 0.163825\tvalid_1's rmse: 0.165299\n",
      "[4800]\ttraining's rmse: 0.163668\tvalid_1's rmse: 0.165186\n",
      "[4900]\ttraining's rmse: 0.163524\tvalid_1's rmse: 0.165083\n",
      "[5000]\ttraining's rmse: 0.163384\tvalid_1's rmse: 0.164989\n",
      "[5100]\ttraining's rmse: 0.163253\tvalid_1's rmse: 0.164901\n",
      "[5200]\ttraining's rmse: 0.163127\tvalid_1's rmse: 0.16482\n",
      "[5300]\ttraining's rmse: 0.162996\tvalid_1's rmse: 0.164733\n",
      "[5400]\ttraining's rmse: 0.162876\tvalid_1's rmse: 0.164655\n",
      "[5500]\ttraining's rmse: 0.162744\tvalid_1's rmse: 0.16457\n",
      "[5600]\ttraining's rmse: 0.162617\tvalid_1's rmse: 0.164486\n",
      "[5700]\ttraining's rmse: 0.162514\tvalid_1's rmse: 0.164424\n",
      "[5800]\ttraining's rmse: 0.162399\tvalid_1's rmse: 0.164354\n",
      "[5900]\ttraining's rmse: 0.162289\tvalid_1's rmse: 0.164288\n",
      "[6000]\ttraining's rmse: 0.162183\tvalid_1's rmse: 0.164225\n",
      "[6100]\ttraining's rmse: 0.162075\tvalid_1's rmse: 0.164162\n",
      "[6200]\ttraining's rmse: 0.161968\tvalid_1's rmse: 0.164096\n",
      "[6300]\ttraining's rmse: 0.161869\tvalid_1's rmse: 0.164042\n",
      "[6400]\ttraining's rmse: 0.161765\tvalid_1's rmse: 0.163982\n",
      "[6500]\ttraining's rmse: 0.161662\tvalid_1's rmse: 0.163924\n",
      "[6600]\ttraining's rmse: 0.161564\tvalid_1's rmse: 0.16387\n",
      "[6700]\ttraining's rmse: 0.161466\tvalid_1's rmse: 0.163817\n",
      "[6800]\ttraining's rmse: 0.161366\tvalid_1's rmse: 0.163762\n",
      "[6900]\ttraining's rmse: 0.161264\tvalid_1's rmse: 0.163704\n",
      "[7000]\ttraining's rmse: 0.161167\tvalid_1's rmse: 0.163648\n",
      "[7100]\ttraining's rmse: 0.161075\tvalid_1's rmse: 0.1636\n",
      "[7200]\ttraining's rmse: 0.160977\tvalid_1's rmse: 0.163543\n",
      "[7300]\ttraining's rmse: 0.160888\tvalid_1's rmse: 0.163494\n",
      "[7400]\ttraining's rmse: 0.160804\tvalid_1's rmse: 0.163454\n",
      "[7500]\ttraining's rmse: 0.160712\tvalid_1's rmse: 0.163403\n",
      "[7600]\ttraining's rmse: 0.16062\tvalid_1's rmse: 0.163354\n",
      "[7700]\ttraining's rmse: 0.160533\tvalid_1's rmse: 0.163309\n",
      "[7800]\ttraining's rmse: 0.160442\tvalid_1's rmse: 0.163258\n",
      "[7900]\ttraining's rmse: 0.160364\tvalid_1's rmse: 0.163221\n",
      "[8000]\ttraining's rmse: 0.160285\tvalid_1's rmse: 0.163181\n",
      "[8100]\ttraining's rmse: 0.160202\tvalid_1's rmse: 0.163141\n",
      "[8200]\ttraining's rmse: 0.160112\tvalid_1's rmse: 0.163092\n",
      "[8300]\ttraining's rmse: 0.160036\tvalid_1's rmse: 0.163058\n",
      "[8400]\ttraining's rmse: 0.159962\tvalid_1's rmse: 0.163026\n",
      "[8500]\ttraining's rmse: 0.159882\tvalid_1's rmse: 0.162986\n",
      "[8600]\ttraining's rmse: 0.159808\tvalid_1's rmse: 0.162955\n",
      "[8700]\ttraining's rmse: 0.159731\tvalid_1's rmse: 0.162919\n",
      "[8800]\ttraining's rmse: 0.159661\tvalid_1's rmse: 0.16289\n",
      "[8900]\ttraining's rmse: 0.15958\tvalid_1's rmse: 0.162846\n",
      "[9000]\ttraining's rmse: 0.15951\tvalid_1's rmse: 0.162818\n",
      "[9100]\ttraining's rmse: 0.159432\tvalid_1's rmse: 0.162781\n",
      "[9200]\ttraining's rmse: 0.159361\tvalid_1's rmse: 0.162752\n",
      "[9300]\ttraining's rmse: 0.159287\tvalid_1's rmse: 0.162718\n",
      "[9400]\ttraining's rmse: 0.159214\tvalid_1's rmse: 0.162688\n",
      "[9500]\ttraining's rmse: 0.159138\tvalid_1's rmse: 0.162652\n",
      "[9600]\ttraining's rmse: 0.15907\tvalid_1's rmse: 0.162624\n",
      "[9700]\ttraining's rmse: 0.159003\tvalid_1's rmse: 0.162598\n",
      "[9800]\ttraining's rmse: 0.158934\tvalid_1's rmse: 0.162569\n",
      "[9900]\ttraining's rmse: 0.158858\tvalid_1's rmse: 0.162533\n",
      "[10000]\ttraining's rmse: 0.15878\tvalid_1's rmse: 0.162496\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's rmse: 0.15878\tvalid_1's rmse: 0.162496\n",
      "Partial score of fold 3 is: 0.9354192394246678\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.997205\tvalid_1's rmse: 0.996464\n",
      "[200]\ttraining's rmse: 0.410455\tvalid_1's rmse: 0.410409\n",
      "[300]\ttraining's rmse: 0.234163\tvalid_1's rmse: 0.2346\n",
      "[400]\ttraining's rmse: 0.193833\tvalid_1's rmse: 0.194452\n",
      "[500]\ttraining's rmse: 0.18461\tvalid_1's rmse: 0.185286\n",
      "[600]\ttraining's rmse: 0.1813\tvalid_1's rmse: 0.182004\n",
      "[700]\ttraining's rmse: 0.179443\tvalid_1's rmse: 0.180165\n",
      "[800]\ttraining's rmse: 0.178091\tvalid_1's rmse: 0.178861\n",
      "[900]\ttraining's rmse: 0.176886\tvalid_1's rmse: 0.177698\n",
      "[1000]\ttraining's rmse: 0.175904\tvalid_1's rmse: 0.176758\n",
      "[1100]\ttraining's rmse: 0.175052\tvalid_1's rmse: 0.175953\n",
      "[1200]\ttraining's rmse: 0.174237\tvalid_1's rmse: 0.175182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\ttraining's rmse: 0.173558\tvalid_1's rmse: 0.174546\n",
      "[1400]\ttraining's rmse: 0.172904\tvalid_1's rmse: 0.173933\n",
      "[1500]\ttraining's rmse: 0.172305\tvalid_1's rmse: 0.173379\n",
      "[1600]\ttraining's rmse: 0.171733\tvalid_1's rmse: 0.172853\n",
      "[1700]\ttraining's rmse: 0.171256\tvalid_1's rmse: 0.172424\n",
      "[1800]\ttraining's rmse: 0.17075\tvalid_1's rmse: 0.171963\n",
      "[1900]\ttraining's rmse: 0.170319\tvalid_1's rmse: 0.171585\n",
      "[2000]\ttraining's rmse: 0.169913\tvalid_1's rmse: 0.171231\n",
      "[2100]\ttraining's rmse: 0.169525\tvalid_1's rmse: 0.170893\n",
      "[2200]\ttraining's rmse: 0.169154\tvalid_1's rmse: 0.170576\n",
      "[2300]\ttraining's rmse: 0.168806\tvalid_1's rmse: 0.170279\n",
      "[2400]\ttraining's rmse: 0.168491\tvalid_1's rmse: 0.170014\n",
      "[2500]\ttraining's rmse: 0.168163\tvalid_1's rmse: 0.169736\n",
      "[2600]\ttraining's rmse: 0.167887\tvalid_1's rmse: 0.169511\n",
      "[2700]\ttraining's rmse: 0.167612\tvalid_1's rmse: 0.169285\n",
      "[2800]\ttraining's rmse: 0.167355\tvalid_1's rmse: 0.16908\n",
      "[2900]\ttraining's rmse: 0.16709\tvalid_1's rmse: 0.168865\n",
      "[3000]\ttraining's rmse: 0.16684\tvalid_1's rmse: 0.168663\n",
      "[3100]\ttraining's rmse: 0.166602\tvalid_1's rmse: 0.168475\n",
      "[3200]\ttraining's rmse: 0.166365\tvalid_1's rmse: 0.168289\n",
      "[3300]\ttraining's rmse: 0.166136\tvalid_1's rmse: 0.16811\n",
      "[3400]\ttraining's rmse: 0.165906\tvalid_1's rmse: 0.167931\n",
      "[3500]\ttraining's rmse: 0.165696\tvalid_1's rmse: 0.16777\n",
      "[3600]\ttraining's rmse: 0.165477\tvalid_1's rmse: 0.167602\n",
      "[3700]\ttraining's rmse: 0.165282\tvalid_1's rmse: 0.167456\n",
      "[3800]\ttraining's rmse: 0.165098\tvalid_1's rmse: 0.167323\n",
      "[3900]\ttraining's rmse: 0.164924\tvalid_1's rmse: 0.167194\n",
      "[4000]\ttraining's rmse: 0.164756\tvalid_1's rmse: 0.167074\n",
      "[4100]\ttraining's rmse: 0.164581\tvalid_1's rmse: 0.166948\n",
      "[4200]\ttraining's rmse: 0.164417\tvalid_1's rmse: 0.166831\n",
      "[4300]\ttraining's rmse: 0.164259\tvalid_1's rmse: 0.166719\n",
      "[4400]\ttraining's rmse: 0.164105\tvalid_1's rmse: 0.166614\n",
      "[4500]\ttraining's rmse: 0.163959\tvalid_1's rmse: 0.166518\n",
      "[4600]\ttraining's rmse: 0.163816\tvalid_1's rmse: 0.166424\n",
      "[4700]\ttraining's rmse: 0.163671\tvalid_1's rmse: 0.166324\n",
      "[4800]\ttraining's rmse: 0.163527\tvalid_1's rmse: 0.166228\n",
      "[4900]\ttraining's rmse: 0.163392\tvalid_1's rmse: 0.166144\n",
      "[5000]\ttraining's rmse: 0.163262\tvalid_1's rmse: 0.16606\n",
      "[5100]\ttraining's rmse: 0.163127\tvalid_1's rmse: 0.16597\n",
      "[5200]\ttraining's rmse: 0.162993\tvalid_1's rmse: 0.165885\n",
      "[5300]\ttraining's rmse: 0.162868\tvalid_1's rmse: 0.165807\n",
      "[5400]\ttraining's rmse: 0.162738\tvalid_1's rmse: 0.165722\n",
      "[5500]\ttraining's rmse: 0.162615\tvalid_1's rmse: 0.165646\n",
      "[5600]\ttraining's rmse: 0.162491\tvalid_1's rmse: 0.165571\n",
      "[5700]\ttraining's rmse: 0.162372\tvalid_1's rmse: 0.165501\n",
      "[5800]\ttraining's rmse: 0.162254\tvalid_1's rmse: 0.165427\n",
      "[5900]\ttraining's rmse: 0.162137\tvalid_1's rmse: 0.165355\n",
      "[6000]\ttraining's rmse: 0.162032\tvalid_1's rmse: 0.165295\n",
      "[6100]\ttraining's rmse: 0.161915\tvalid_1's rmse: 0.165221\n",
      "[6200]\ttraining's rmse: 0.161799\tvalid_1's rmse: 0.165154\n",
      "[6300]\ttraining's rmse: 0.161701\tvalid_1's rmse: 0.165105\n",
      "[6400]\ttraining's rmse: 0.161597\tvalid_1's rmse: 0.165047\n",
      "[6500]\ttraining's rmse: 0.1615\tvalid_1's rmse: 0.164993\n",
      "[6600]\ttraining's rmse: 0.161392\tvalid_1's rmse: 0.164926\n",
      "[6700]\ttraining's rmse: 0.161287\tvalid_1's rmse: 0.164866\n",
      "[6800]\ttraining's rmse: 0.161189\tvalid_1's rmse: 0.164813\n",
      "[6900]\ttraining's rmse: 0.161098\tvalid_1's rmse: 0.164766\n",
      "[7000]\ttraining's rmse: 0.161009\tvalid_1's rmse: 0.164721\n",
      "[7100]\ttraining's rmse: 0.160921\tvalid_1's rmse: 0.164678\n",
      "[7200]\ttraining's rmse: 0.160826\tvalid_1's rmse: 0.164627\n",
      "[7300]\ttraining's rmse: 0.160728\tvalid_1's rmse: 0.164574\n",
      "[7400]\ttraining's rmse: 0.16063\tvalid_1's rmse: 0.16452\n",
      "[7500]\ttraining's rmse: 0.160534\tvalid_1's rmse: 0.164469\n",
      "[7600]\ttraining's rmse: 0.160442\tvalid_1's rmse: 0.164419\n",
      "[7700]\ttraining's rmse: 0.16035\tvalid_1's rmse: 0.164371\n",
      "[7800]\ttraining's rmse: 0.160266\tvalid_1's rmse: 0.164332\n",
      "[7900]\ttraining's rmse: 0.160177\tvalid_1's rmse: 0.164284\n",
      "[8000]\ttraining's rmse: 0.160088\tvalid_1's rmse: 0.164237\n",
      "[8100]\ttraining's rmse: 0.160005\tvalid_1's rmse: 0.164198\n",
      "[8200]\ttraining's rmse: 0.159924\tvalid_1's rmse: 0.164159\n",
      "[8300]\ttraining's rmse: 0.15985\tvalid_1's rmse: 0.164125\n",
      "[8400]\ttraining's rmse: 0.159769\tvalid_1's rmse: 0.164089\n",
      "[8500]\ttraining's rmse: 0.159692\tvalid_1's rmse: 0.164054\n",
      "[8600]\ttraining's rmse: 0.159611\tvalid_1's rmse: 0.164017\n",
      "[8700]\ttraining's rmse: 0.159531\tvalid_1's rmse: 0.163981\n",
      "[8800]\ttraining's rmse: 0.159451\tvalid_1's rmse: 0.163942\n",
      "[8900]\ttraining's rmse: 0.159376\tvalid_1's rmse: 0.163909\n",
      "[9000]\ttraining's rmse: 0.159296\tvalid_1's rmse: 0.163874\n",
      "[9100]\ttraining's rmse: 0.159228\tvalid_1's rmse: 0.163846\n",
      "[9200]\ttraining's rmse: 0.159158\tvalid_1's rmse: 0.163819\n",
      "[9300]\ttraining's rmse: 0.159084\tvalid_1's rmse: 0.163787\n",
      "[9400]\ttraining's rmse: 0.15901\tvalid_1's rmse: 0.163755\n",
      "[9500]\ttraining's rmse: 0.158939\tvalid_1's rmse: 0.163726\n",
      "[9600]\ttraining's rmse: 0.158862\tvalid_1's rmse: 0.163694\n",
      "[9700]\ttraining's rmse: 0.158793\tvalid_1's rmse: 0.163666\n",
      "[9800]\ttraining's rmse: 0.158718\tvalid_1's rmse: 0.163631\n",
      "[9900]\ttraining's rmse: 0.158655\tvalid_1's rmse: 0.16361\n",
      "[10000]\ttraining's rmse: 0.158589\tvalid_1's rmse: 0.163584\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's rmse: 0.158589\tvalid_1's rmse: 0.163584\n",
      "Partial score of fold 4 is: 0.9346255366200137\n",
      "Our macroF1 is:  0.9349827066076305\n"
     ]
    }
   ],
   "source": [
    "lgb_model = Lgb_Model(train_df, test_df, features, categoricals=categoricals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds=lgb_model.y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_proc(pred):\n",
    "    pred = np.round(np.clip(pred, 0, 10))\n",
    "    return pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds=pred_proc(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hevy code. In kaggle submission, this code should be comment-out\n",
    "y_train_pred=lgb_model.model.predict(train_df[features])#, num_iteration=lgb_model.model.best_iteration) #default =100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred=pred_proc(y_train_pred)\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "train_df[\"y_pred\"]=y_train_pred\n",
    "train_df.to_csv('lgb_originalsignal_y_pred_rev1.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "      <th>open_channels</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>-2.7600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0002</td>\n",
       "      <td>-2.8557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0003</td>\n",
       "      <td>-2.4074</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>-3.1404</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0005</td>\n",
       "      <td>-3.1525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     time  signal  open_channels  y_pred\n",
       "0  0.0001 -2.7600              0       0\n",
       "1  0.0002 -2.8557              0       0\n",
       "2  0.0003 -2.4074              0       0\n",
       "3  0.0004 -3.1404              0       0\n",
       "4  0.0005 -3.1525              0       0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predictions distribution')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_preds);\n",
    "plt.title('Predictions distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df['open_channels'] = test_preds\n",
    "submission_df.to_csv('submission.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "002d0c75ca2b4e24afda9b96f007cd21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1ec6601701f84182b54b95e59c141dc3",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1e838811b8f44c57b57b37cf646c9d84",
       "value": 3
      }
     },
     "1e838811b8f44c57b57b37cf646c9d84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "1ec6601701f84182b54b95e59c141dc3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "285c4c38976546aa8b5f7ef301eee7dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "29b63f05977b4be1978a5009aef7980a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_507940deb3224fb0844de1207bd5253a",
        "IPY_MODEL_37cdf380a3db42ca8c0b4896b23117b8"
       ],
       "layout": "IPY_MODEL_71184de51ca34ab0902f32f7b45f2da7"
      }
     },
     "37cdf380a3db42ca8c0b4896b23117b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_85b5416f585643ad929effb68ab0649f",
       "placeholder": "​",
       "style": "IPY_MODEL_60923f0033e84c7393218f2c58522aaa",
       "value": " 3/3 [10:52&lt;00:00, 217.63s/it]"
      }
     },
     "507940deb3224fb0844de1207bd5253a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f7ff0f2c1ae9466b97f197436717fb47",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a36ef07bb0f14ae5adc2ebc17f3968ff",
       "value": 3
      }
     },
     "60923f0033e84c7393218f2c58522aaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "71184de51ca34ab0902f32f7b45f2da7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8248fdc6482c4aa5ac48cfe1e01cf9aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85b5416f585643ad929effb68ab0649f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a36ef07bb0f14ae5adc2ebc17f3968ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c17eb229b9e14b4a8ed317e2793d0bef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8248fdc6482c4aa5ac48cfe1e01cf9aa",
       "placeholder": "​",
       "style": "IPY_MODEL_e83f715e1d5b4182be171d17a3bfc557",
       "value": " 3/3 [04:05&lt;00:00, 81.92s/it]"
      }
     },
     "e83f715e1d5b4182be171d17a3bfc557": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f7ff0f2c1ae9466b97f197436717fb47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fa4b5fda2eab41f49fd82bffecb41b3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_002d0c75ca2b4e24afda9b96f007cd21",
        "IPY_MODEL_c17eb229b9e14b4a8ed317e2793d0bef"
       ],
       "layout": "IPY_MODEL_285c4c38976546aa8b5f7ef301eee7dd"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
